#!/usr/bin/env bash
SCRIPT_START=$SECONDS

# GRAVITY SYNC BY VMSTAN #####################
PROGRAM='Gravity Sync'
VERSION='4.0.0'

# For documentation or downloading updates visit https://github.com/vmstan/gravity-sync
# Requires Pi-Hole 5.x or higher already be installed, for help visit https://pi-hole.net

# REQUIRED SETTINGS ##########################

# Run 'gravity-sync config' to get started, it will customize the script for your environment
# You should not to change the values of any variables here here to customize your install
# Add replacement variables to gravity-sync.conf, which will overwrite these defaults.
# Gravity Sync 4.0 introduces a new configuration file format, there is no direct upgrade path

# CUSTOM VARIABLES ###########################

# Installation Types - Standard install is 'default' - Containers must be 'docker' or 'podman'
LOCAL_PIHOLE_TYPE='default'				        # replace in gravity-sync.conf to overwrite
REMOTE_PIHOLE_TYPE='default'				    # replace in gravity-sync.conf to overwrite

# Pi-hole Folder/File Customization - Only need to be customized when using containers
LOCAL_PIHOLE_DIRECTORY='/etc/pihole' 			# replace in gravity-sync.conf to overwrite
REMOTE_PIHOLE_DIRECTORY='/etc/pihole'			# replace in gravity-sync.conf to overwrite
LOCAL_DNSMASQ_DIRECTORY='/etc/dnsmasq.d'        # replace in gravity-sync.conf to overwrite
REMOTE_DNSMASQ_DIRECTORY='/etc/dnsmasq.d'       # replace in gravity-sync.conf to overwrite
LOCAL_FILE_OWNER='pihole:pihole'			    # replace in gravity-sync.conf to overwrite
REMOTE_FILE_OWNER='pihole:pihole'			    # replace in gravity-sync.conf to overwrite

# Pi-hole Docker/Podman container name - Docker will pattern match anything set below
LOCAL_DOCKER_CONTAINER='pihole'					# replace in gravity-sync.conf to overwrite
REMOTE_DOCKER_CONTAINER='pihole'				# replace in gravity-sync.conf to overwrite

# STANDARD VARIABLES #########################

DEFAULT_PIHOLE_DIRECTORY='/etc/pihole'			# Default Pi-hole data directory
LOCAL_PIHOLE_BINARY='/usr/local/bin/pihole' 	# Local Pi-hole binary directory (default)
REMOTE_PIHOLE_BINARY='/usr/local/bin/pihole' 	# Remote Pi-hole binary directory (default)
LOCAL_FTL_BINARY='/usr/bin/pihole-FTL'          # Local FTL binary directory (default)
REMOTE_FTL_BINARY='/usr/bin/pihole-FTL'         # Remote FTL binary directory (default)
LOCAL_DOCKER_BINARY='/usr/bin/docker'		    # Local Docker binary directory (default)
REMOTE_DOCKER_BINARY='/usr/bin/docker'		    # Remote Docker binary directory (default)
LOCAL_PODMAN_BINARY='/usr/bin/podman'           # Local Podman binary directory (default)
REMOTE_PODMAN_BINARY='/usr/bin/podman'          # Remote Podman binary directory (default)
PIHOLE_CONTAINER_IMAGE='pihole/pihole'          # Official Pi-hole container image name

PH_GRAVITY_FI='gravity.db' 			            # Pi-hole database file name
PH_CUSTOM_DNS='custom.list'			            # Pi-hole DNS lookup filename
PH_CNAME_CONF='05-pihole-custom-cname.conf'     # DNSMASQ CNAME alias file

# Backup Customization
GS_BACKUP_TIMEOUT='240'                         # replace in gravity-sync.conf to overwrite
GS_BACKUP_INTEGRITY_WAIT='5'                    # replace in gravity-sync.conf to overwrite
GS_BACKUP_EXT='gsb'                             # replace in gravity-sync.conf to overwrite

# GS Folder/File Locations
GS_FILEPATH='/usr/local/bin/gravity-sync'			
GS_ETC_PATH="/etc/gravity-sync"		            # replace in gravity-sync.conf to overwrite
GS_CONFIG_FILE='gravity-sync.conf' 	            # replace in gravity-sync.conf to overwrite
GS_SYNCING_LOG='gravity-sync.log' 		        # replace in gravity-sync.conf to overwrite
GS_GRAVITY_FI_MD5_LOG='gravity.md5'             # replace in gravity-sync.conf to overwrite
GS_CUSTOM_DNS_MD5_LOG='clist.md5'               # replace in gravity-sync.conf to overwrite
GS_CNAME_CONF_MD5_LOG='cname.md5'               # replace in gravity-sync.conf to overwrite

# SSH Customization
GS_SSH_PORT='22' 						            # replace in gravity-sync.conf to overwrite
GS_SSH_PKIF="${GS_ETC_PATH}/gravity-sync.rsa"      # replace in gravity-sync.conf to overwrite

# Github Customization
GS_LOCAL_REPO="${GS_ETC_PATH}/.gs"              # replace in gravity-sync.conf to overwrite

# OS Settings
OS_DAEMON_PATH='/etc/systemd/system'               # replace in gravity-sync.conf to overwrite
OS_TMP='/tmp'                                   # replace in gravity-sync.conf to overwrite

##############################################
### NEVER CHANGE ANYTHING BELOW THIS LINE! ###
##############################################

# Interface Settings
UI_GRAVITY_NAME='Gravity Database'
UI_CUSTOM_NAME='DNS Records'
UI_CNAME_NAME='DNS CNAMEs'

# Core
UI_CORE_LOADING='Loading'
UI_CORE_EVALUATING='Evaluating arguments'
UI_CORE_INIT="Initalizing ${PROGRAM} (${VERSION})"
UI_CORE_APP='Pi-hole'
UI_CORE_APP_DNS='DNSMASQ'

# Exit
UI_EXIT_CALC_END='after'
UI_EXIT_ABORT='exited'
UI_EXIT_COMPLETE='completed'
UI_EXIT_CALC_TIMER='seconds'

# Hashing
UI_HASHING_HASHING='Hashing the remote'
UI_HASHING_COMPARING='Comparing to the local'
UI_HASHING_DIFFERNCE='Differences detected in the'
UI_HASHING_DETECTED='has been detected on the'
UI_HASHING_NOTDETECTED='not detected on the'
UI_HASHING_REMOTE="remote ${UI_CORE_APP}"
UI_HASHING_LOCAL="local ${UI_CORE_APP}"
UI_HASHING_REHASHING='Rehashing the remote'
UI_HASHING_RECOMPARING='Recomparing to local'

# Validation
UI_VALIDATING='Validating pathways to'
UI_VALIDATING_FAIL_CONTAINER='Unable to validate running container instance of'
UI_VALIDATING_FAIL_FOLDER='Unable to validate configuration folder for'
UI_VALIDATING_FAIL_BINARY='Unable to validate the availibility of'
UI_SET_LOCAL_FILE_OWNERSHIP='Setting file ownership on'
UI_SET_FILE_PERMISSION='Setting file permissions on'

# Pull/Push
UI_PULL_REMOTE='Pulling the remote'
UI_PUSH_LOCAL='Pushing the local'
UI_REPLACE_LOCAL='Replacing the local'
UI_FTLDNS_CONFIG_PULL_RELOAD='Reloading local FTLDNS services'
UI_FTLDNS_CONFIG_PUSH_RELOAD='Reloading remote FTLDNS services'

# Logging
UI_LOGGING_RECENT_COMPLETE='Recent complete executions of'

# Backup
UI_BACKUP_REMOTE='Performing backup of remote'
UI_BACKUP_LOCAL='Performing backup of local'
UI_BACKUP_INTEGRITY="Checking ${UI_GRAVITY_NAME} copy integrity"
UI_BACKUP_INTEGRITY_FAILED='Integrity check has failed for the remote'
UI_BACKUP_INTEGRITY_DELETE='Removing failed copies'

# Configuration
UI_CONFIG_YESNON="'Yes' or 'No', blank is default 'No'"
UI_CONFIG_ALREADY='already exists'
UI_CONFIG_AREYOUSURE='Proceeding will replace your existing configuration'
UI_CONFIG_DOADVANCED='Do you want to enable advanced installation options'
UI_CONFIG_ERASING='Erasing existing'
UI_CONFIG_CREATING='Creating new'
UI_CONFIG_REQUIRED='required settings'
UI_CONFIG_ADVANCED='advanced settings'
UI_CONFIG_REMOTE='remote host'
UI_CONFIG_LOCAL='local host'
UI_CONFIG_HOSTREQ='address required'
UI_CONFIG_USERREQ='SSH user required'
UI_CONFIG_CONT_LOOKUP='Looking for container engines'
UI_CONFIG_CONT_DETECT='Docker or Podman container engine'
UI_CONFIG_CONT_DETECTED='detected'
UI_CONFIG_CONT_DETECTNA='not detected'
UI_CONFIG_SSH_KEYPAIR='Key-pair registered to'
UI_CONFIG_LOCALSEC='Local'
UI_CONFIG_REMOTEPRI='Remote'
UI_CONFIG_INSTANCEREQ='instance type required'
UI_CONFIG_INSTANCENAME='instance name required'
UI_CONFIG_INSTANCETYPE="'docker' or 'podman' container, or blank for default install"
UI_CONFIG_CONTAINER_TYPE='container type'
UI_CONFIG_CONTAINER_NAME='container name'
UI_CONFIG_INSTANCE_ERROR="${UI_CONFIG_CONTAINER_TYPE} must either be 'docker' or 'podman'"
UI_CONFIG_IMAGES='running instances'
UI_CONFIG_SAVING='Saving'
UI_CONFIG_PIHOLE_DEFAULT="Container name or blank for default 'pihole'"
UI_CONFIG_ETC_VOLPATH="'etc' volume path"
UI_CONFIG_ETC_VOLPATH_EXAMPLE="Example, '/opt/pihole/etc-pihole'"
UI_CONFIG_ETC_VOLDNSQ_EXAMPLE="Example, '/opt/pihole/etc-dnsmasq.d'"
UI_CONFIG_SETTING_REQUIRED='This setting is required!'
UI_CONFIG_VOLUME_OWNER='volume ownership'
UI_CONFIG_DEFAULT_LEAVE="Leave blank for default"

## Script Colors
RED='\033[0;91m'
GREEN='\033[0;92m'
CYAN='\033[0;96m'
YELLOW='\033[0;93m'
PURPLE='\033[0;95m'
BLUE='\033[0;94m'
BOLD='\033[1m'
NC='\033[0m'

## Message Codes
FAIL="${RED}✗${NC}"
WARN="${PURPLE}!${NC}"
GOOD="${GREEN}✓${NC}"
STAT="${CYAN}∞${NC}"
INFO="${YELLOW}»${NC}"
INF1="${CYAN}›${NC}"
NEED="${BLUE}?${NC}"
LOGO="${PURPLE}∞${NC}"

## Echo Stack
### Informative
function echo_info {
    echo -e "${INFO} ${YELLOW}${MESSAGE}${NC}"
}

function echo_inf1 {
    echo -e "${INF1} ${CYAN}${MESSAGE}${NC}"
}

### Warning
function echo_warn {
    echo -e "${WARN} ${PURPLE}${MESSAGE}${NC}"
}

### Executing
function echo_stat {
    echo -en "${STAT} ${MESSAGE}"
}

### Success
function echo_good {
    echo -e "\r${GOOD} ${MESSAGE}"
}

### Success
function echo_good_clean {
    echo -e "\r${GOOD} ${MESSAGE}"
}

### Failure
function echo_fail {
    echo -e "\r${FAIL} ${MESSAGE}"
}

### Request
function echo_need {
    echo -en "${NEED} ${BOLD}${MESSAGE}:${NC} "
}

### Gravity Sync Logo
function echo_grav {
    echo -e "${LOGO} ${BOLD}${MESSAGE}${NC}"
}

### Lines
function echo_lines {
    echo -e "∞∞∞∞∞∞∞∞∞∞∞∞∞∞∞∞∞∞∞∞∞∞∞∞∞∞∞∞∞∞∞∞∞∞∞∞∞∞∞"
}

### Lines
function echo_blank {
    echo -e ""
}

# Standard Output
function start_gs {
    MESSAGE="${UI_CORE_INIT}"
    echo_grav
    # cd ${LOCAL_FOLDR}
    
    import_gs_config
    set_pihole_exec
    
    MESSAGE="${UI_CORE_EVALUATING}"
    echo_stat
    
    validate_sudo_status
}

# Standard Output No Config
function start_gs_noconfig {
    MESSAGE="${UI_CORE_INIT}"
    echo_grav
    
    MESSAGE="${UI_CORE_EVALUATING}"
    echo_stat
}

## Import Settings
function import_gs_config {
    MESSAGE="${UI_CORE_LOADING} ${GS_CONFIG_FILE}"
    echo -en "${STAT} $MESSAGE"
    if [ -f ${GS_ETC_PATH}/${GS_CONFIG_FILE} ]; then
        source ${GS_ETC_PATH}/${GS_CONFIG_FILE}
        error_validate
    else
        echo_fail
        
        MESSAGE="Missing ${GS_CONFIG_FILE}"
        echo_inf1
        
        TASKTYPE='CONFIG'
        config_generate
    fi
}

## Invalid Tasks
function task_invalid {
    echo_fail
    list_gs_arguments
}

## Error Validation
function error_validate {
    if [ "$?" != "0" ]; then
        echo_fail
        exit 1
    else
        echo_good
    fi
}

function  set_pihole_exec {
    if [ "$LOCAL_PIHOLE_TYPE" == "default" ]; then
        PH_EXEC="${LOCAL_PIHOLE_BINARY}"
        FTL_EXEC="${LOCAL_FTL_BINARY}"
    elif [ "$LOCAL_PIHOLE_TYPE" == "docker" ]; then
        PH_EXEC="sudo ${LOCAL_DOCKER_BINARY} exec $(sudo ${LOCAL_DOCKER_BINARY} ps -qf name=${LOCAL_DOCKER_CONTAINER}) pihole"
        FTL_EXEC="sudo ${LOCAL_DOCKER_BINARY} exec $(sudo ${LOCAL_DOCKER_BINARY} ps -qf name=${LOCAL_DOCKER_CONTAINER}) pihole-FTL"
    elif [ "$LOCAL_PIHOLE_TYPE" == "podman" ]; then
        PH_EXEC="sudo ${LOCAL_PODMAN_BINARY} exec ${LOCAL_DOCKER_CONTAINER} pihole"
        FTL_EXEC="sudo ${LOCAL_PODMAN_BINARY} exec ${LOCAL_DOCKER_CONTAINER} pihole-FTL"
    fi
    
    if [ "$REMOTE_PIHOLE_TYPE" == "default" ]; then
        RH_EXEC="${REMOTE_PIHOLE_BINARY}"
        RFTL_EXEC="${REMOTE_FTL_BINARY}"
    elif [ "$REMOTE_PIHOLE_TYPE" == "docker" ]; then
        RH_EXEC="sudo ${REMOTE_DOCKER_BINARY} exec \$(sudo ${REMOTE_DOCKER_BINARY} ps -qf name=${REMOTE_DOCKER_CONTAINER}) pihole"
        RFTL_EXEC="sudo ${REMOTE_DOCKER_BINARY} exec \$(sudo ${REMOTE_DOCKER_BINARY} ps -qf name=${REMOTE_DOCKER_CONTAINER}) pihole-FTL"
    elif [ "$REMOTE_PIHOLE_TYPE" == "podman" ]; then
        RH_EXEC="sudo ${REMOTE_PODMAN_BINARY} exec ${REMOTE_DOCKER_CONTAINER} pihole"
        RFTL_EXEC="sudo ${REMOTE_PODMAN_BINARY} exec ${REMOTE_DOCKER_CONTAINER} pihole"
    fi
}

## Compare Task
function task_compare {
    TASKTYPE='COMPARE'
    MESSAGE="${MESSAGE}: ${TASKTYPE}"
    echo_good
    
    show_target
    validate_ph_folders
    validate_dns_folders
    validate_os_sshpass
    previous_md5
    md5_compare
    exit_withchange
}

## Pull Task
function task_pull {
    TASKTYPE='PULL'
    MESSAGE="${MESSAGE}: ${TASKTYPE}"
    echo_good
    show_target
    validate_ph_folders
    validate_dns_folders
    validate_os_sshpass
    pull_gs
    exit
}

## Pull Gravity
function pull_gs_grav {
    
    backup_local_gravity
    backup_remote_gravity
    backup_remote_gravity_integrity
    
    MESSAGE="${UI_PULL_REMOTE} ${UI_GRAVITY_NAME}"
    echo_stat
    RSYNC_REPATH="sudo rsync"
    RSYNC_SOURCE="${REMOTE_USER}@${REMOTE_HOST}:${REMOTE_PIHOLE_DIRECTORY}/${PH_GRAVITY_FI}.${GS_BACKUP_EXT}"
    RSYNC_TARGET="${OS_TMP}/${PH_GRAVITY_FI}.${GS_BACKUP_EXT}"
    create_rsynccmd
    
    MESSAGE="${UI_REPLACE_LOCAL} ${UI_GRAVITY_NAME}"
    echo_stat
    sudo mv ${OS_TMP}/${PH_GRAVITY_FI}.${GS_BACKUP_EXT} ${LOCAL_PIHOLE_DIRECTORY}/${PH_GRAVITY_FI} >/dev/null 2>&1
    error_validate
    
    validate_gravity_permissions
}

## Pull Custom
function pull_gs_cust {
    if [ "$REMOTE_PH_CUSTOM_DNS" == "1" ]; then
        backup_local_custom
        backup_remote_custom
        
        MESSAGE="${UI_PULL_REMOTE} ${UI_CUSTOM_NAME}"
        echo_stat
        RSYNC_REPATH="sudo rsync"
        RSYNC_SOURCE="${REMOTE_USER}@${REMOTE_HOST}:${REMOTE_PIHOLE_DIRECTORY}/${PH_CUSTOM_DNS}.${GS_BACKUP_EXT}"
        RSYNC_TARGET="${OS_TMP}/${PH_CUSTOM_DNS}.${GS_BACKUP_EXT}"
        create_rsynccmd
        
        MESSAGE="${UI_REPLACE_LOCAL} ${UI_CUSTOM_NAME}"
        echo_stat
        sudo mv ${OS_TMP}/${PH_CUSTOM_DNS}.${GS_BACKUP_EXT} ${LOCAL_PIHOLE_DIRECTORY}/${PH_CUSTOM_DNS} >/dev/null 2>&1
        error_validate
        
        validate_custom_permissions
    fi
}

## Pull CNAME
function pull_gs_cname {
    if [ "$REMOTE_CNAME_DNS" == "1" ]; then
        backup_local_cname
        backup_remote_cname
        
        MESSAGE="${UI_PULL_REMOTE} ${UI_CNAME_NAME}"
        echo_stat
        RSYNC_REPATH="sudo rsync"
        RSYNC_SOURCE="${REMOTE_USER}@${REMOTE_HOST}:${REMOTE_PIHOLE_DIRECTORY}/${PH_CNAME_CONF}.${GS_BACKUP_EXT}"
        RSYNC_TARGET="${OS_TMP}/${PH_CNAME_CONF}.${GS_BACKUP_EXT}"
        create_rsynccmd
        
        MESSAGE="${UI_REPLACE_LOCAL} ${UI_CNAME_NAME}"
        echo_stat
        sudo mv ${OS_TMP}/${PH_CNAME_CONF}.${GS_BACKUP_EXT} ${LOCAL_DNSMASQ_DIRECTORY}/${PH_CNAME_CONF} >/dev/null 2>&1
        error_validate
        
        validate_cname_permissions
    fi
}

## Pull Reload
function pull_gs_reload {
    sleep 1
    
    MESSAGE="Updating local FTLDNS configuration"
    echo_stat
    ${PH_EXEC} restartdns reload-lists >/dev/null 2>&1
    error_validate
    
    if [ "${TASKTYPE}" == SMART ]; then 
        if [ "${REMOTE_DNS_CHANGE}" == "1" ] || [ "${LOCAL_DNS_CHANGE}" == "1" ] || [ "${REMOTE_CNAME_CHANGE}" == "1" ] || [ "${LOCAL_CNAME_CHANGE}" == "1" ]; then
            MESSAGE="${UI_FTLDNS_CONFIG_PULL_RELOAD}"
            echo_stat
            ${PH_EXEC} restartdns >/dev/null 2>&1
            error_validate
        fi
    else
        MESSAGE="${UI_FTLDNS_CONFIG_PULL_RELOAD}"
        echo_stat
        ${PH_EXEC} restartdns >/dev/null 2>&1
        error_validate
    fi
}

## Pull Function
function pull_gs {
    previous_md5
    md5_compare
    pull_gs_grav
    pull_gs_cust
    pull_gs_cname
    pull_gs_reload
    md5_recheck
    logs_export
    exit_withchange
}

## Push Task
function task_push {
    TASKTYPE='PUSH'
    MESSAGE="${MESSAGE}: ${TASKTYPE}"
    echo_good
    
    show_target
    validate_ph_folders
    validate_dns_folders
    validate_os_sshpass
    push_gs
    exit
}

## Push Gravity
function push_gs_grav {
    backup_remote_gravity
    backup_local_gravity
    backup_local_gravity_integrity
    
    MESSAGE="${UI_PUSH_LOCAL} ${UI_GRAVITY_NAME}"
    echo_stat
    RSYNC_REPATH="sudo rsync"
    RSYNC_SOURCE="${LOCAL_PIHOLE_DIRECTORY}/${PH_GRAVITY_FI}.${GS_BACKUP_EXT}"
    RSYNC_TARGET="${REMOTE_USER}@${REMOTE_HOST}:${REMOTE_PIHOLE_DIRECTORY}/${PH_GRAVITY_FI}"
    create_rsynccmd
    
    MESSAGE="${UI_SET_LOCAL_FILE_OWNERSHIP} ${UI_GRAVITY_NAME}"
    echo_stat
    CMD_TIMEOUT=$GS_BACKUP_TIMEOUT
    CMD_REQUESTED="sudo chown ${REMOTE_FILE_OWNER} ${REMOTE_PIHOLE_DIRECTORY}/${PH_GRAVITY_FI}"
    create_sshcmd
    
    MESSAGE="${UI_SET_FILE_PERMISSION} ${UI_GRAVITY_NAME}"
    echo_stat
    CMD_TIMEOUT=$GS_BACKUP_TIMEOUT
    CMD_REQUESTED="sudo chmod 664 ${REMOTE_PIHOLE_DIRECTORY}/${PH_GRAVITY_FI}"
    create_sshcmd
}

## Push Custom
function push_gs_cust {
    if [ "$REMOTE_PH_CUSTOM_DNS" == "1" ]; then
        backup_remote_custom
        backup_local_custom
        
        MESSAGE="${UI_PUSH_LOCAL} ${UI_CUSTOM_NAME}"
        echo_stat
        RSYNC_REPATH="sudo rsync"
        RSYNC_SOURCE="${LOCAL_PIHOLE_DIRECTORY}/${PH_CUSTOM_DNS}.${GS_BACKUP_EXT}"
        RSYNC_TARGET="${REMOTE_USER}@${REMOTE_HOST}:${REMOTE_PIHOLE_DIRECTORY}/${PH_CUSTOM_DNS}"
        create_rsynccmd
        
        MESSAGE="${UI_SET_LOCAL_FILE_OWNERSHIP} ${UI_CUSTOM_NAME}"
        echo_stat
        CMD_TIMEOUT=$GS_BACKUP_TIMEOUT
        CMD_REQUESTED="sudo chown root:root ${REMOTE_PIHOLE_DIRECTORY}/${PH_CUSTOM_DNS}"
        create_sshcmd
        
        MESSAGE="${UI_SET_FILE_PERMISSION} ${UI_CUSTOM_NAME}"
        echo_stat
        CMD_TIMEOUT=$GS_BACKUP_TIMEOUT
        CMD_REQUESTED="sudo chmod 644 ${REMOTE_PIHOLE_DIRECTORY}/${PH_CUSTOM_DNS}"
        create_sshcmd
    fi
}

## Push Custom
function push_gs_cname {
    if [ "$REMOTE_CNAME_DNS" == "1" ]; then
        backup_remote_cname
        backup_local_cname
        
        MESSAGE="${UI_PUSH_LOCAL} ${UI_CNAME_NAME}"
        echo_stat
        RSYNC_REPATH="sudo rsync"
        RSYNC_SOURCE="${LOCAL_PIHOLE_DIRECTORY}/${PH_CNAME_CONF}.${GS_BACKUP_EXT}"
        RSYNC_TARGET="${REMOTE_USER}@${REMOTE_HOST}:${REMOTE_DNSMASQ_DIRECTORY}/${PH_CNAME_CONF}"
        create_rsynccmd
        
        MESSAGE="${UI_SET_LOCAL_FILE_OWNERSHIP} ${UI_CNAME_NAME}"
        echo_stat
        CMD_TIMEOUT=$GS_BACKUP_TIMEOUT
        CMD_REQUESTED="sudo chown root:root ${REMOTE_DNSMASQ_DIRECTORY}/${PH_CNAME_CONF}"
        create_sshcmd
        
                    
        MESSAGE="${UI_SET_FILE_PERMISSION} ${UI_CNAME_NAME}"
        echo_stat
        CMD_TIMEOUT=$GS_BACKUP_TIMEOUT
        CMD_REQUESTED="sudo chmod 644 ${REMOTE_DNSMASQ_DIRECTORY}/${PH_CNAME_CONF}"
        create_sshcmd
    fi
}

## Push Reload
function push_gs_reload {
    sleep 1
    
    MESSAGE="Updating remote FTLDNS configuration"
    echo_stat
    CMD_TIMEOUT=$GS_BACKUP_TIMEOUT
    CMD_REQUESTED="${RH_EXEC} restartdns reload-lists"
    create_sshcmd
    
    if [ "${TASKTYPE}" == SMART ]; then 
        if [ "${REMOTE_DNS_CHANGE}" == "1" ] || [ "${LOCAL_DNS_CHANGE}" == "1" ] || [ "${REMOTE_CNAME_CHANGE}" == "1" ] || [ "${LOCAL_CNAME_CHANGE}" == "1" ]; then
            MESSAGE="${UI_FTLDNS_CONFIG_PUSH_RELOAD}"
            echo_stat
            CMD_TIMEOUT=$GS_BACKUP_TIMEOUT
            CMD_REQUESTED="${RH_EXEC} restartdns"
            create_sshcmd
        fi
    else
        MESSAGE="${UI_FTLDNS_CONFIG_PUSH_RELOAD}"
        echo_stat
        CMD_TIMEOUT=$GS_BACKUP_TIMEOUT
        CMD_REQUESTED="${RH_EXEC} restartdns"
        create_sshcmd
    fi
}

## Push Function
function push_gs {
    previous_md5
    md5_compare
    push_gs_grav
    push_gs_cust
    push_gs_cname
    push_gs_reload
    md5_recheck
    logs_export
    exit_withchange
}

## Smart Task
function task_smart {
    TASKTYPE='SMART'
    MESSAGE="${MESSAGE}: ${TASKTYPE}"
    echo_good
    
    show_target
    validate_ph_folders
    validate_dns_folders
    validate_os_sshpass
    smart_gs
    exit
}

## Smart Sync Function
function smart_gs {
    MESSAGE="Starting ${TASKTYPE} Analysis"
    echo_info
    
    previous_md5
    md5_compare
    
    REMOTE_GRAVITY_CHANGE="0"
    LOCAL_GRAVITY_CHANGE="0"
    REMOTE_DNS_CHANGE="0"
    LOCAL_DNS_CHANGE="0"
    REMOTE_CNAME_CHANGE="0"
    LOCAL_CNAME_CHANGE="0"
    
    if [ "${REMOTE_DB_MD5}" != "${LAST_REMOTE_DB_MD5}" ]; then
        REMOTE_GRAVITY_CHANGE="1"
    fi
    
    if [ "${LOCAL_DB_MD5}" != "${LAST_LOCAL_DB_MD5}" ]; then
        LOCAL_GRAVITY_CHANGE="1"
    fi
    
    if [ "${REMOTE_GRAVITY_CHANGE}" == "${LOCAL_GRAVITY_CHANGE}" ]; then
        if [ "${REMOTE_GRAVITY_CHANGE}" != "0" ]; then
            MESSAGE="Both ${UI_GRAVITY_NAME} have changed"
            echo_warn
            
            REMOTE_GRAVITY_DATE=$(${SSHPASSWORD} ${SSH_CMD} -p ${GS_SSH_PORT} -i "${GS_SSH_PKIF}" ${REMOTE_USER}@${REMOTE_HOST} "stat -c %Y ${REMOTE_PIHOLE_DIRECTORY}/${PH_GRAVITY_FI}")
            LOCAL_GRAVITY_DATE=$(stat -c %Y ${LOCAL_PIHOLE_DIRECTORY}/${PH_GRAVITY_FI})
            
            if (( "$REMOTE_GRAVITY_DATE" >= "$LOCAL_GRAVITY_DATE" )); then
                MESSAGE="Remote ${UI_GRAVITY_NAME} was last changed"
                echo_warn
                
                pull_gs_grav
                PULLRESTART="1"
            else
                MESSAGE="Local ${UI_GRAVITY_NAME} was last changed"
                echo_warn
                
                push_gs_grav
                PUSHRESTART="1"
            fi
        fi
    else
        if [ "${REMOTE_GRAVITY_CHANGE}" != "0" ]; then
            pull_gs_grav
            PULLRESTART="1"
        elif [ "${LOCAL_GRAVITY_CHANGE}" != "0" ]; then
            push_gs_grav
            PUSHRESTART="1"
        fi
    fi
    
    if [ "${REMOTE_CL_MD5}" != "${LAST_REMOTE_CL_MD5}" ]; then
        REMOTE_DNS_CHANGE="1"
    fi
    
    if [ "${LOCAL_CL_MD5}" != "${LAST_LOCAL_CL_MD5}" ]; then
        LOCAL_DNS_CHANGE="1"
    fi
    
    if [ -f "${LOCAL_PIHOLE_DIRECTORY}/${PH_CUSTOM_DNS}" ]; then
        if [ "${REMOTE_DNS_CHANGE}" == "${LOCAL_DNS_CHANGE}" ]; then
            if [ "${REMOTE_DNS_CHANGE}" != "0" ]; then
                MESSAGE="Both ${UI_CUSTOM_NAME} have changed"
                echo_warn
                
                REMOTE_DNS_DATE=$(${SSHPASSWORD} ${SSH_CMD} -p ${GS_SSH_PORT} -i "${GS_SSH_PKIF}" ${REMOTE_USER}@${REMOTE_HOST} "stat -c %Y ${REMOTE_PIHOLE_DIRECTORY}/${PH_CUSTOM_DNS}")
                LOCAL_DNS_DATE=$(stat -c %Y ${LOCAL_PIHOLE_DIRECTORY}/${PH_CUSTOM_DNS})
                
                if (( "$REMOTE_DNS_DATE" >= "$LOCAL_DNS_DATE" )); then
                    MESSAGE="Remote ${UI_CUSTOM_NAME} was last changed"
                    echo_warn
                    
                    pull_gs_cust
                    PULLRESTART="1"
                else
                    MESSAGE="Local ${UI_CUSTOM_NAME} was last changed"
                    echo_warn
                    
                    push_gs_cust
                    PUSHRESTART="1"
                fi
            fi
        else
            if [ "${REMOTE_DNS_CHANGE}" != "0" ]; then
                pull_gs_cust
                PULLRESTART="1"
            elif [ "${LOCAL_DNS_CHANGE}" != "0" ]; then
                push_gs_cust
                PUSHRESTART="1"
            fi
        fi
    else
        pull_gs_cust
        PULLRESTART="1"
    fi
    
    if [ "${REMOTE_CN_MD5}" != "${LAST_REMOTE_CN_MD5}" ]; then
        REMOTE_CNAME_CHANGE="1"
    fi
    
    if [ "${LOCAL_CN_MD5}" != "${LAST_LOCAL_CN_MD5}" ]; then
        LOCAL_CNAME_CHANGE="1"
    fi
    
    if [ -f "${LOCAL_DNSMASQ_DIRECTORY}/${PH_CNAME_CONF}" ]; then
        if [ "${REMOTE_CNAME_CHANGE}" == "${LOCAL_CNAME_CHANGE}" ]; then
            if [ "${REMOTE_CNAME_CHANGE}" != "0" ]; then
                MESSAGE="Both ${UI_CNAME_NAME} have Changed"
                echo_warn
                
                REMOTE_CNAME_DATE=$(${SSHPASSWORD} ${SSH_CMD} -p ${GS_SSH_PORT} -i "${GS_SSH_PKIF}" ${REMOTE_USER}@${REMOTE_HOST} "stat -c %Y ${REMOTE_DNSMASQ_DIRECTORY}/${PH_CNAME_CONF}")
                LOCAL_CNAME_DATE=$(stat -c %Y ${LOCAL_DNSMASQ_DIRECTORY}/${PH_CNAME_CONF})
                
                if (( "$REMOTE_CNAME_DATE" >= "$LOCAL_CNAME_DATE" )); then
                    MESSAGE="Remote ${UI_CNAME_NAME} was last changed"
                    echo_warn
                    
                    pull_gs_cname
                    PULLRESTART="1"
                else
                    MESSAGE="Local ${UI_CNAME_NAME} was last changed"
                    echo_warn
                    
                    push_gs_cname
                    PUSHRESTART="1"
                fi
            fi
        else
            if [ "${REMOTE_CNAME_CHANGE}" != "0" ]; then
                pull_gs_cname
                PULLRESTART="1"
            elif [ "${LOCAL_CNAME_CHANGE}" != "0" ]; then
                push_gs_cname
                PUSHRESTART="1"
            fi
        fi
    else
        pull_gs_cname
        PULLRESTART="1"
    fi
    
    if [ "$PULLRESTART" == "1" ]; then
        pull_gs_reload
    fi
    
    if [ "$PUSHRESTART" == "1" ]; then
        push_gs_reload
    fi
    
    md5_recheck
    
    logs_export
    exit_withchange
}

function backup_local_gravity() {
    MESSAGE="${UI_BACKUP_LOCAL} ${UI_GRAVITY_NAME}"
    echo_stat
    
    if [ "$LOCAL_PIHOLE_TYPE" == "default" ]; then
        sudo ${FTL_EXEC} sql ${LOCAL_PIHOLE_DIRECTORY}/${PH_GRAVITY_FI} ".backup '${LOCAL_PIHOLE_DIRECTORY}/${PH_GRAVITY_FI}.${GS_BACKUP_EXT}'"
        error_validate
    elif [ "$LOCAL_PIHOLE_TYPE" == "docker" ]; then
        sudo ${FTL_EXEC} sql ${DEFAULT_PIHOLE_DIRECTORY}/${PH_GRAVITY_FI} ".backup '${DEFAULT_PIHOLE_DIRECTORY}/${PH_GRAVITY_FI}.${GS_BACKUP_EXT}'"
        error_validate
    elif [ "$LOCAL_PIHOLE_TYPE" == "podman" ]; then
        sudo ${FTL_EXEC} sql ${DEFAULT_PIHOLE_DIRECTORY}/${PH_GRAVITY_FI} ".backup '${DEFAULT_PIHOLE_DIRECTORY}/${PH_GRAVITY_FI}.${GS_BACKUP_EXT}'"
        error_validate
    fi
}

function backup_local_gravity_integrity() {
    MESSAGE="${UI_BACKUP_INTEGRITY}"
    echo_stat
    
    sleep $GS_BACKUP_INTEGRITY_WAIT

    if [ "$LOCAL_PIHOLE_TYPE" == "default" ]; then
        LOCAL_INTEGRITY_CHECK=$(${FTL_EXEC} sql ${LOCAL_PIHOLE_DIRECTORY}/${PH_GRAVITY_FI}.${GS_BACKUP_EXT} 'PRAGMA integrity_check;' | sed 's/\s.*$//')
        error_validate
    elif [ "$LOCAL_PIHOLE_TYPE" == "docker" ]; then
        LOCAL_INTEGRITY_CHECK=$(${FTL_EXEC} sql ${DEFAULT_PIHOLE_DIRECTORY}/${PH_GRAVITY_FI}.${GS_BACKUP_EXT} 'PRAGMA integrity_check;' | sed 's/\s.*$//')
        error_validate
    elif [ "$LOCAL_PIHOLE_TYPE" == "podman" ]; then
        LOCAL_INTEGRITY_CHECK=$(${FTL_EXEC} sql ${DEFAULT_PIHOLE_DIRECTORY}/${PH_GRAVITY_FI}.${GS_BACKUP_EXT} 'PRAGMA integrity_check;' | sed 's/\s.*$//')
        error_validate
    fi
    
    if [ "$LOCAL_INTEGRITY_CHECK" != 'ok' ]; then
        MESSAGE="${UI_BACKUP_INTEGRITY_FAILED} ${UI_GRAVITY_NAME}"
        echo_fail
        
        MESSAGE="${UI_BACKUP_INTEGRITY_DELETE} ${UI_GRAVITY_NAME}"
        echo_stat
            
        sudo rm ${LOCAL_PIHOLE_DIRECTORY}/${PH_GRAVITY_FI}.${GS_BACKUP_EXT}
        error_validate
        
        exit_nochange
    fi
}

function backup_local_custom() {
    if [ -f ${LOCAL_PIHOLE_DIRECTORY}/${PH_CUSTOM_DNS} ]; then
        MESSAGE="${UI_BACKUP_LOCAL} ${UI_CUSTOM_NAME}"
        echo_stat
        
        sudo cp ${LOCAL_PIHOLE_DIRECTORY}/${PH_CUSTOM_DNS} ${LOCAL_PIHOLE_DIRECTORY}/${PH_CUSTOM_DNS}.${GS_BACKUP_EXT}
        error_validate
    else
        MESSAGE="No local ${PH_CUSTOM_DNS} detected"
        echo_inf1
    fi
}

function backup_local_cname() {
    if [ -f ${LOCAL_DNSMASQ_DIRECTORY}/${PH_CNAME_CONF} ]; then
        MESSAGE="${UI_BACKUP_LOCAL} ${UI_CNAME_NAME}"
        echo_stat
        
        sudo cp ${LOCAL_DNSMASQ_DIRECTORY}/${PH_CNAME_CONF} ${LOCAL_PIHOLE_DIRECTORY}/${PH_CNAME_CONF}.${GS_BACKUP_EXT}
        error_validate
    else
        MESSAGE="No local ${PH_CNAME_CONF} detected"
        echo_inf1
    fi
}

function backup_remote_gravity() {
    MESSAGE="${UI_BACKUP_REMOTE} ${UI_GRAVITY_NAME}"
    echo_stat

    if [ "$REMOTE_PIHOLE_TYPE" == "default" ]; then
        CMD_TIMEOUT=$GS_BACKUP_TIMEOUT
        CMD_REQUESTED="sudo ${RFTL_EXEC} sql ${REMOTE_PIHOLE_DIRECTORY}/${PH_GRAVITY_FI} \".backup '${REMOTE_PIHOLE_DIRECTORY}/${PH_GRAVITY_FI}.${GS_BACKUP_EXT}'\""
        create_sshcmd
    elif [ "$REMOTE_PIHOLE_TYPE" == "docker" ]; then
        CMD_TIMEOUT=$GS_BACKUP_TIMEOUT
        CMD_REQUESTED="sudo ${RFTL_EXEC} sql ${DEFAULT_PIHOLE_DIRECTORY}/${PH_GRAVITY_FI} \".backup '${DEFAULT_PIHOLE_DIRECTORY}/${PH_GRAVITY_FI}.${GS_BACKUP_EXT}'\""
        create_sshcmd
    elif [ "$REMOTE_PIHOLE_TYPE" == "podman" ]; then
        CMD_TIMEOUT=$GS_BACKUP_TIMEOUT
        CMD_REQUESTED="sudo ${RFTL_EXEC} sql ${DEFAULT_PIHOLE_DIRECTORY}/${PH_GRAVITY_FI} \".backup '${DEFAULT_PIHOLE_DIRECTORY}/${PH_GRAVITY_FI}.${GS_BACKUP_EXT}'\""
        create_sshcmd
    fi
}

function backup_remote_gravity_integrity() {
    MESSAGE="${UI_BACKUP_INTEGRITY}"
    echo_stat
    
    sleep $GS_BACKUP_INTEGRITY_WAIT

    if [ "$REMOTE_PIHOLE_TYPE" == "default" ]; then
        REMOTE_INTEGRITY_CHECK=$(${SSHPASSWORD} ${SSH_CMD} -p ${GS_SSH_PORT} -i "${GS_SSH_PKIF}" ${REMOTE_USER}@${REMOTE_HOST} "${RFTL_EXEC} sql ${REMOTE_PIHOLE_DIRECTORY}/${PH_GRAVITY_FI}.${GS_BACKUP_EXT} 'PRAGMA integrity_check;'" | sed 's/\s.*$//')
        error_validate
    elif [ "$REMOTE_PIHOLE_TYPE" == "docker" ]; then
        REMOTE_INTEGRITY_CHECK=$(${SSHPASSWORD} ${SSH_CMD} -p ${GS_SSH_PORT} -i "${GS_SSH_PKIF}" ${REMOTE_USER}@${REMOTE_HOST} "${RFTL_EXEC} sql ${DEFAULT_PIHOLE_DIRECTORY}/${PH_GRAVITY_FI}.${GS_BACKUP_EXT} 'PRAGMA integrity_check;'" | sed 's/\s.*$//')
        error_validate
    elif [ "$REMOTE_PIHOLE_TYPE" == "podman" ]; then
        REMOTE_INTEGRITY_CHECK=$(${SSHPASSWORD} ${SSH_CMD} -p ${GS_SSH_PORT} -i "${GS_SSH_PKIF}" ${REMOTE_USER}@${REMOTE_HOST} "${RFTL_EXEC} sql ${DEFAULT_PIHOLE_DIRECTORY}/${PH_GRAVITY_FI}.${GS_BACKUP_EXT} 'PRAGMA integrity_check;'" | sed 's/\s.*$//')
        error_validate
    fi
    
    if [ "$REMOTE_INTEGRITY_CHECK" != 'ok' ]; then
        MESSAGE="${UI_BACKUP_INTEGRITY_FAILED} ${UI_GRAVITY_NAME}"
        echo_fail
        
        MESSAGE="${UI_BACKUP_INTEGRITY_DELETE} ${UI_GRAVITY_NAME}"
        echo_stat
        
        CMD_TIMEOUT=$GS_BACKUP_TIMEOUT
        CMD_REQUESTED="sudo rm ${REMOTE_PIHOLE_DIRECTORY}/${PH_GRAVITY_FI}.${GS_BACKUP_EXT}"
        create_sshcmd
        
        exit_nochange
    fi
}

function backup_remote_custom() {
        MESSAGE="${UI_BACKUP_REMOTE} ${UI_CUSTOM_NAME}"
        echo_stat
        
        CMD_TIMEOUT=$GS_BACKUP_TIMEOUT
        CMD_REQUESTED="sudo cp ${REMOTE_PIHOLE_DIRECTORY}/${PH_CUSTOM_DNS} ${REMOTE_PIHOLE_DIRECTORY}/${PH_CUSTOM_DNS}.${GS_BACKUP_EXT}"
        create_sshcmd
}

function backup_remote_cname() {
        MESSAGE="${UI_BACKUP_REMOTE} ${UI_CNAME_NAME}"
        echo_stat
        
        CMD_TIMEOUT=$GS_BACKUP_TIMEOUT
        CMD_REQUESTED="sudo cp ${REMOTE_DNSMASQ_DIRECTORY}/${PH_CNAME_CONF} ${REMOTE_PIHOLE_DIRECTORY}/${PH_CNAME_CONF}.${GS_BACKUP_EXT}"
        create_sshcmd
}

function backup_cleanup() {
    MESSAGE="Purging backups"
    echo_stat
    # git clean -fq
    sudo rm -f ${LOCAL_PIHOLE_DIRECTORY}/*.${GS_BACKUP_EXT}
    error_validate

    # MESSAGE="${UI_BACKUP_PURGE} on remote"
    # echo_stat
    # CMD_TIMEOUT=$GS_BACKUP_TIMEOUT
    # CMD_REQUESTED="sudo rm -f ${REMOTE_PIHOLE_DIRECTORY}/*.${GS_BACKUP_EXT}"
    # create_sshcmd
}

function md5_compare {
    HASHMARK='0'
    
    MESSAGE="${UI_HASHING_HASHING} ${UI_GRAVITY_NAME}"
    echo_stat
    REMOTE_DB_MD5=$(${SSHPASSWORD} ${SSH_CMD} -p ${GS_SSH_PORT} -i "${GS_SSH_PKIF}" ${REMOTE_USER}@${REMOTE_HOST} "md5sum ${REMOTE_PIHOLE_DIRECTORY}/${PH_GRAVITY_FI}" | sed 's/\s.*$//')
    error_validate
    
    MESSAGE="${UI_HASHING_COMPARING} ${UI_GRAVITY_NAME}"
    echo_stat
    LOCAL_DB_MD5=$(md5sum ${LOCAL_PIHOLE_DIRECTORY}/${PH_GRAVITY_FI} | sed 's/\s.*$//')
    error_validate
    
    if [ "$REMOTE_DB_MD5" == "$LAST_REMOTE_DB_MD5" ] && [ "$LOCAL_DB_MD5" == "$LAST_LOCAL_DB_MD5" ]; then
        HASHMARK=$((HASHMARK+0))
    else
        MESSAGE="${UI_HASHING_DIFFERNCE} ${UI_GRAVITY_NAME}"
        echo_warn
        HASHMARK=$((HASHMARK+1))
    fi
    
    if [ -f ${LOCAL_PIHOLE_DIRECTORY}/${PH_CUSTOM_DNS} ]; then
        if ${SSHPASSWORD} ${SSH_CMD} -p ${GS_SSH_PORT} -i "${GS_SSH_PKIF}" ${REMOTE_USER}@${REMOTE_HOST} test -e ${REMOTE_PIHOLE_DIRECTORY}/${PH_CUSTOM_DNS}; then
            REMOTE_PH_CUSTOM_DNS="1"
            MESSAGE="${UI_HASHING_HASHING} ${UI_CUSTOM_NAME}"
            echo_stat
            
            REMOTE_CL_MD5=$(${SSHPASSWORD} ${SSH_CMD} -p ${GS_SSH_PORT} -i "${GS_SSH_PKIF}" ${REMOTE_USER}@${REMOTE_HOST} "md5sum ${REMOTE_PIHOLE_DIRECTORY}/${PH_CUSTOM_DNS} | sed 's/\s.*$//'")
            error_validate
            
            MESSAGE="${UI_HASHING_COMPARING} ${UI_CUSTOM_NAME}"
            echo_stat
            LOCAL_CL_MD5=$(md5sum ${LOCAL_PIHOLE_DIRECTORY}/${PH_CUSTOM_DNS} | sed 's/\s.*$//')
            error_validate
            
            if [ "$REMOTE_CL_MD5" == "$LAST_REMOTE_CL_MD5" ] && [ "$LOCAL_CL_MD5" == "$LAST_LOCAL_CL_MD5" ]; then
                HASHMARK=$((HASHMARK+0))
            else
                MESSAGE="${UI_HASHING_DIFFERNCE} ${UI_CUSTOM_NAME}"
                echo_warn
                HASHMARK=$((HASHMARK+1))
            fi
        else
            MESSAGE="${UI_CUSTOM_NAME} ${UI_HASHING_NOTDETECTED} ${UI_HASHING_REMOTE}"
            echo_inf1
        fi
    else
        if ${SSHPASSWORD} ${SSH_CMD} -p ${GS_SSH_PORT} -i "${GS_SSH_PKIF}" ${REMOTE_USER}@${REMOTE_HOST} test -e ${REMOTE_PIHOLE_DIRECTORY}/${PH_CUSTOM_DNS}; then
            REMOTE_PH_CUSTOM_DNS="1"
            MESSAGE="${UI_CUSTOM_NAME} ${UI_HASHING_DETECTED} ${UI_HASHING_REMOTE}"
            HASHMARK=$((HASHMARK+1))
            echo_inf1
        fi
        MESSAGE="${UI_CUSTOM_NAME} ${UI_HASHING_NOTDETECTED} ${UI_HASHING_LOCAL}"
        echo_inf1
    fi

    if [ -f ${LOCAL_DNSMASQ_DIRECTORY}/${PH_CNAME_CONF} ]; then
        if ${SSHPASSWORD} ${SSH_CMD} -p ${GS_SSH_PORT} -i "${GS_SSH_PKIF}" ${REMOTE_USER}@${REMOTE_HOST} test -e ${REMOTE_DNSMASQ_DIRECTORY}/${PH_CNAME_CONF}; then
            REMOTE_CNAME_DNS="1"
            MESSAGE="${UI_HASHING_HASHING} ${UI_CNAME_NAME}"
            echo_stat
            
            REMOTE_CN_MD5=$(${SSHPASSWORD} ${SSH_CMD} -p ${GS_SSH_PORT} -i "${GS_SSH_PKIF}" ${REMOTE_USER}@${REMOTE_HOST} "md5sum ${REMOTE_DNSMASQ_DIRECTORY}/${PH_CNAME_CONF} | sed 's/\s.*$//'")
            error_validate
            
            MESSAGE="${UI_HASHING_COMPARING} ${UI_CNAME_NAME}"
            echo_stat
            LOCAL_CN_MD5=$(md5sum ${LOCAL_DNSMASQ_DIRECTORY}/${PH_CNAME_CONF} | sed 's/\s.*$//')
            error_validate
            
            if [ "$REMOTE_CN_MD5" == "$LAST_REMOTE_CN_MD5" ] && [ "$LOCAL_CN_MD5" == "$LAST_LOCAL_CN_MD5" ]; then
                HASHMARK=$((HASHMARK+0))
            else
                MESSAGE="${UI_HASHING_DIFFERNCE} ${UI_CNAME_NAME}"
                echo_warn
                HASHMARK=$((HASHMARK+1))
            fi
        else
            MESSAGE="${UI_CNAME_NAME} ${UI_HASHING_NOTDETECTED} ${UI_HASHING_REMOTE}"
            echo_inf1
        fi
    else
        if ${SSHPASSWORD} ${SSH_CMD} -p ${GS_SSH_PORT} -i "${GS_SSH_PKIF}" ${REMOTE_USER}@${REMOTE_HOST} test -e ${REMOTE_DNSMASQ_DIRECTORY}/${PH_CNAME_CONF}; then
            REMOTE_CNAME_DNS="1"
            MESSAGE="${UI_CNAME_NAME} ${UI_HASHING_DETECTED} ${UI_HASHING_REMOTE}"
            HASHMARK=$((HASHMARK+1))
            echo_inf1
        fi
        
        MESSAGE="${UI_CNAME_NAME} ${UI_HASHING_NOTDETECTED} ${UI_HASHING_LOCAL}"
        echo_inf1
    fi
    
    if [ "$HASHMARK" != "0" ]; then
        MESSAGE="Replication of ${UI_CORE_APP} settings is required"
        echo_warn
        HASHMARK=$((HASHMARK+0))
    else
        MESSAGE="No replication is required at this time"
        echo_inf1
        exit_nochange
    fi
}

function previous_md5 {
    if [ -f "${GS_ETC_PATH}/${GS_GRAVITY_FI_MD5_LOG}" ]; then
        LAST_REMOTE_DB_MD5=$(sed "1q;d" ${GS_ETC_PATH}/${GS_GRAVITY_FI_MD5_LOG})
        LAST_LOCAL_DB_MD5=$(sed "2q;d" ${GS_ETC_PATH}/${GS_GRAVITY_FI_MD5_LOG})
    else
        LAST_REMOTE_DB_MD5="0"
        LAST_LOCAL_DB_MD5="0"
    fi

    if [ -f "${GS_ETC_PATH}/${GS_CUSTOM_DNS_MD5_LOG}" ]; then
        LAST_REMOTE_CL_MD5=$(sed "1q;d" ${GS_ETC_PATH}/${GS_CUSTOM_DNS_MD5_LOG})
        LAST_LOCAL_CL_MD5=$(sed "2q;d" ${GS_ETC_PATH}/${GS_CUSTOM_DNS_MD5_LOG})
    else
        LAST_REMOTE_CL_MD5="0"
        LAST_LOCAL_CL_MD5="0"
    fi

    if [ -f "${GS_ETC_PATH}/${GS_CNAME_CONF_MD5_LOG}" ]; then
        LAST_REMOTE_CN_MD5=$(sed "1q;d" ${GS_ETC_PATH}/${GS_CNAME_CONF_MD5_LOG})
        LAST_LOCAL_CN_MD5=$(sed "2q;d" ${GS_ETC_PATH}/${GS_CNAME_CONF_MD5_LOG})
    else
        LAST_REMOTE_CN_MD5="0"
        LAST_LOCAL_CN_MD5="0"
    fi
}

function md5_recheck {
    MESSAGE="Performing replicator diagnostics"
    echo_inf1
    
    HASHMARK='0'
    
    MESSAGE="${UI_HASHING_REHASHING} ${UI_GRAVITY_NAME}"
    echo_stat
    REMOTE_DB_MD5=$(${SSHPASSWORD} ${SSH_CMD} -p ${GS_SSH_PORT} -i "${GS_SSH_PKIF}" ${REMOTE_USER}@${REMOTE_HOST} "md5sum ${REMOTE_PIHOLE_DIRECTORY}/${PH_GRAVITY_FI}" | sed 's/\s.*$//')
    error_validate
    
    MESSAGE="${UI_HASHING_RECOMPARING} ${UI_GRAVITY_NAME}"
    echo_stat
    LOCAL_DB_MD5=$(md5sum ${LOCAL_PIHOLE_DIRECTORY}/${PH_GRAVITY_FI} | sed 's/\s.*$//')
    error_validate
    
    if [ -f ${LOCAL_PIHOLE_DIRECTORY}/${PH_CUSTOM_DNS} ]; then
        if ${SSHPASSWORD} ${SSH_CMD} -p ${GS_SSH_PORT} -i "${GS_SSH_PKIF}" ${REMOTE_USER}@${REMOTE_HOST} test -e ${REMOTE_PIHOLE_DIRECTORY}/${PH_CUSTOM_DNS}; then
            REMOTE_PH_CUSTOM_DNS="1"
            MESSAGE="${UI_HASHING_REHASHING} ${UI_CUSTOM_NAME}"
            echo_stat
            
            REMOTE_CL_MD5=$(${SSHPASSWORD} ${SSH_CMD} -p ${GS_SSH_PORT} -i "${GS_SSH_PKIF}" ${REMOTE_USER}@${REMOTE_HOST} "md5sum ${REMOTE_PIHOLE_DIRECTORY}/${PH_CUSTOM_DNS} | sed 's/\s.*$//'")
            error_validate
            
            MESSAGE="${UI_HASHING_RECOMPARING} ${UI_CUSTOM_NAME}"
            echo_stat
            LOCAL_CL_MD5=$(md5sum ${LOCAL_PIHOLE_DIRECTORY}/${PH_CUSTOM_DNS} | sed 's/\s.*$//')
            error_validate
        else
            MESSAGE="${UI_CUSTOM_NAME} ${UI_HASHING_NOTDETECTED} ${UI_HASHING_REMOTE}"
            echo_inf1
        fi
    else
        if ${SSHPASSWORD} ${SSH_CMD} -p ${GS_SSH_PORT} -i "${GS_SSH_PKIF}" ${REMOTE_USER}@${REMOTE_HOST} test -e ${REMOTE_PIHOLE_DIRECTORY}/${PH_CUSTOM_DNS}; then
            REMOTE_PH_CUSTOM_DNS="1"
            MESSAGE="${UI_CUSTOM_NAME} ${UI_HASHING_DETECTED} ${UI_HASHING_REMOTE}"
            echo_inf1
        fi
        MESSAGE="${UI_CUSTOM_NAME} ${UI_HASHING_NOTDETECTED} ${UI_HASHING_LOCAL}"
        echo_inf1
    fi
    
    if [ -f ${LOCAL_DNSMASQ_DIRECTORY}/${PH_CNAME_CONF} ]; then
        if ${SSHPASSWORD} ${SSH_CMD} -p ${GS_SSH_PORT} -i "${GS_SSH_PKIF}" ${REMOTE_USER}@${REMOTE_HOST} test -e ${REMOTE_DNSMASQ_DIRECTORY}/${PH_CNAME_CONF}; then
            REMOTE_CNAME_DNS="1"
            MESSAGE="${UI_HASHING_REHASHING} ${UI_CNAME_NAME}"
            echo_stat
            
            REMOTE_CN_MD5=$(${SSHPASSWORD} ${SSH_CMD} -p ${GS_SSH_PORT} -i "${GS_SSH_PKIF}" ${REMOTE_USER}@${REMOTE_HOST} "md5sum ${REMOTE_DNSMASQ_DIRECTORY}/${PH_CNAME_CONF} | sed 's/\s.*$//'")
            error_validate
            
            MESSAGE="${UI_HASHING_RECOMPARING} ${UI_CNAME_NAME}"
            echo_stat
            LOCAL_CN_MD5=$(md5sum ${LOCAL_DNSMASQ_DIRECTORY}/${PH_CNAME_CONF} | sed 's/\s.*$//')
            error_validate
        else
            MESSAGE="${UI_CNAME_NAME} ${UI_HASHING_NOTDETECTED} ${UI_HASHING_REMOTE}"
            echo_inf1
        fi
    else
        if ${SSHPASSWORD} ${SSH_CMD} -p ${GS_SSH_PORT} -i "${GS_SSH_PKIF}" ${REMOTE_USER}@${REMOTE_HOST} test -e ${REMOTE_DNSMASQ_DIRECTORY}/${PH_CNAME_CONF}; then
            REMOTE_CNAME_DNS="1"
            MESSAGE="${UI_CNAME_NAME} ${UI_HASHING_NOTDETECTED} ${UI_HASHING_REMOTE}"
            echo_inf1
        fi
        
        MESSAGE="${UI_CNAME_NAME} ${UI_HASHING_NOTDETECTED} ${UI_HASHING_LOCAL}"
        echo_inf1
    fi
}

## Determine SSH Pathways
function create_sshcmd {
    timeout --preserve-status ${CMD_TIMEOUT} ${SSH_CMD} -p ${GS_SSH_PORT} -i ${GS_SSH_PKIF} -o StrictHostKeyChecking=no ${REMOTE_USER}@${REMOTE_HOST} "${CMD_REQUESTED}"
    error_validate
}

## Determine SSH Pathways
function create_rsynccmd {
    rsync --rsync-path="${RSYNC_REPATH}" -e "${SSH_CMD} -p ${GS_SSH_PORT} -i ${GS_SSH_PKIF}" ${RSYNC_SOURCE} ${RSYNC_TARGET} >/dev/null 2>&1
    error_validate
}

function generate_sshkey {
    if [ -z $INPUT_REMOTE_PASS ]; then
        if [ -f ${GS_SSH_PKIF} ]; then
            MESSAGE="Using existing SSH keyfile"
            echo_good_clean
        else
            if hash ssh-keygen >/dev/null 2>&1; then
                MESSAGE="Generating new SSH keyfile"
                echo_stat
                
                ssh-keygen -q -P "" -t rsa -f ${OS_TMP}/gravity-sync.rsa >/dev/null 2>&1
                error_validate

                MESSAGE="Moving private key to ${GS_SSH_PKIF}"
                sudo mv ${OS_TMP}/gravity-sync.rsa ${GS_SSH_PKIF}
                error_validate

                MESSAGE="Moving public key to ${GS_SSH_PKIF}.pub"
                sudo mv ${OS_TMP}/gravity-sync.rsa.pub ${GS_SSH_PKIF}.pub
                error_validate
            else
                MESSAGE="No SSH-KEYGEN available"
                echo_warn
                exit_nochange
            fi
        fi
    fi
}

function export_sshkey {
    if [ -z $REMOTE_PASS ]; then
        if [ -f ${GS_SSH_PKIF} ]; then
            MESSAGE="Registering key-pair to ${REMOTE_HOST}"
            echo_inf1
            
            ssh-copy-id -f -p ${GS_SSH_PORT} -i ${GS_SSH_PKIF}.pub ${REMOTE_USER}@${REMOTE_HOST}
        else
            MESSAGE="Error registering key-pair to ${REMOTE_HOST}"
            echo_warn
        fi
    fi
}

function show_target {
    MESSAGE="Remote ${UI_CORE_APP}: ${REMOTE_USER}@${REMOTE_HOST}"
    echo_inf1
    
    SSH_CMD='ssh'
}

## Logs Task
function task_logs {
    TASKTYPE='LOGS'
    MESSAGE="${MESSAGE}: ${TASKTYPE}"
    echo_good
    logs_gs
}

## Core Logging
### Write Logs Out
function logs_export {
    if [ "${TASKTYPE}" != "BACKUP" ]; then
        MESSAGE="Saving updated data hashses"
        echo_stat
        sudo rm -f ${GS_ETC_PATH}/*.md5
        echo -e ${REMOTE_DB_MD5} | sudo tee -a ${GS_ETC_PATH}/${GS_GRAVITY_FI_MD5_LOG} 1> /dev/null
        echo -e ${LOCAL_DB_MD5} | sudo tee -a ${GS_ETC_PATH}/${GS_GRAVITY_FI_MD5_LOG} 1> /dev/null
        echo -e ${REMOTE_CL_MD5} | sudo tee -a ${GS_ETC_PATH}/${GS_CUSTOM_DNS_MD5_LOG} 1> /dev/null
        echo -e ${LOCAL_CL_MD5} | sudo tee -a ${GS_ETC_PATH}/${GS_CUSTOM_DNS_MD5_LOG} 1> /dev/null
        echo -e ${REMOTE_CN_MD5} | sudo tee -a ${GS_ETC_PATH}/${GS_CNAME_CONF_MD5_LOG} 1> /dev/null
        echo -e ${LOCAL_CN_MD5} | sudo tee -a ${GS_ETC_PATH}/${GS_CNAME_CONF_MD5_LOG} 1> /dev/null
        
        sudo rm -f ${OS_TMP}/*.md5
        echo -e ${LOCAL_DB_MD5} | sudo tee -a ${OS_TMP}/${GS_GRAVITY_FI_MD5_LOG} 1> /dev/null
        echo -e ${REMOTE_DB_MD5} | sudo tee -a ${OS_TMP}/${GS_GRAVITY_FI_MD5_LOG} 1> /dev/null
        echo -e ${LOCAL_CL_MD5} | sudo tee -a ${OS_TMP}/${GS_CUSTOM_DNS_MD5_LOG} 1> /dev/null
        echo -e ${REMOTE_CL_MD5} | sudo tee -a ${OS_TMP}/${GS_CUSTOM_DNS_MD5_LOG} 1> /dev/null
        echo -e ${LOCAL_CN_MD5} | sudo tee -a ${OS_TMP}/${GS_CNAME_CONF_MD5_LOG} 1> /dev/null
        echo -e ${REMOTE_CN_MD5} | sudo tee -a ${OS_TMP}/${GS_CNAME_CONF_MD5_LOG} 1> /dev/null
        error_validate

        MESSAGE="Sending hashes to Gravity Sync peer"
        echo_stat

        RSYNC_REPATH="sudo rsync"
        RSYNC_SOURCE="${OS_TMP}/*.md5"
        RSYNC_TARGET="${REMOTE_USER}@${REMOTE_HOST}:${GS_ETC_PATH}/"
        create_rsynccmd

        MESSAGE="Setting permissions on remote hashing files"
        echo_stat
        CMD_TIMEOUT=$GS_BACKUP_TIMEOUT
        CMD_REQUESTED="sudo chmod 644 ${GS_ETC_PATH}/*.md5"
        create_sshcmd

        sudo rm -f ${OS_TMP}/*.md5
    fi
    
    MESSAGE="Logging successful ${TASKTYPE}"
    echo_stat
    echo -e "$(date) [${TASKTYPE}]" | sudo tee -a ${GS_ETC_PATH}/${GS_SYNCING_LOG} 1> /dev/null
    error_validate
}

### Output Sync Logs
function logs_gs {
    MESSAGE="Displaying output of previous jobs"
    echo_info
    
    echo_lines
    echo -e "${UI_LOGGING_RECENT_COMPLETE} ${YELLOW}SMART${NC}"
    tail -n 7 "${GS_ETC_PATH}/${GS_SYNCING_LOG}" | grep SMART
    echo -e "${UI_LOGGING_RECENT_COMPLETE} ${YELLOW}PULL${NC}"
    tail -n 7 "${GS_ETC_PATH}/${GS_SYNCING_LOG}" | grep PULL
    echo -e "${UI_LOGGING_RECENT_COMPLETE} ${YELLOW}PUSH${NC}"
    tail -n 7 "${GS_ETC_PATH}/${GS_SYNCING_LOG}" | grep PUSH
    echo_lines
    
    exit_nochange
}

## Validate Pi-hole Folders
function validate_ph_folders {
    MESSAGE="${UI_VALIDATING} ${UI_CORE_APP}"
    echo_stat
    
    if [ "$LOCAL_PIHOLE_TYPE" == "default" ]; then
        if [ ! -f ${LOCAL_PIHOLE_BINARY} ]; then
            MESSAGE="${UI_VALIDATING_FAIL_BINARY} ${UI_CORE_APP}"
            echo_fail
            exit_nochange
        fi
    elif [ "$LOCAL_PIHOLE_TYPE" == "docker" ]; then
        FTLCHECK=$(sudo docker container ls | grep "${PIHOLE_CONTAINER_IMAGE}")
        if [ "$FTLCHECK" == "" ]; then
            MESSAGE="${UI_VALIDATING_FAIL_CONTAINER} ${UI_CORE_APP}"
            echo_fail
            exit_nochange
        fi
    elif [ "$LOCAL_PIHOLE_TYPE" == "podman" ]; then
        FTLCHECK=$(sudo podman container ls | grep "${PIHOLE_CONTAINER_IMAGE}")
        if [ "$FTLCHECK" == "" ]; then
            MESSAGE="${UI_VALIDATING_FAIL_CONTAINER} ${UI_CORE_APP}"
            echo_fail
            exit_nochange
        fi
    fi
    
    if [ ! -d ${LOCAL_PIHOLE_DIRECTORY} ]; then
        MESSAGE="${UI_VALIDATING_FAIL_FOLDER} ${UI_CORE_APP}"
        echo_fail
        exit_nochange
    fi
    
    echo_good
}

## Validate DNSMASQ Folders
function validate_dns_folders {
    MESSAGE="${UI_VALIDATING} ${UI_CORE_APP_DNS}"
    echo_stat
    
    if [ ! -d ${LOCAL_DNSMASQ_DIRECTORY} ]; then
        MESSAGE="${UI_VALIDATING_FAIL_FOLDER} ${UI_CORE_APP_DNS}"
        echo_fail
        exit_nochange
    fi
    echo_good
}

## Validate SSHPASS
function validate_os_sshpass {
    MESSAGE="Connecting to ${REMOTE_HOST}"
    echo_stat
    
    CMD_TIMEOUT='5'
    CMD_REQUESTED="exit"
    create_sshcmd
}

## Validate Domain Database Permissions
function validate_gravity_permissions() {
    MESSAGE="${UI_SET_LOCAL_FILE_OWNERSHIP} ${UI_GRAVITY_NAME}"
    echo_stat
    sudo chown ${LOCAL_FILE_OWNER} ${LOCAL_PIHOLE_DIRECTORY}/${PH_GRAVITY_FI} >/dev/null 2>&1
    error_validate
        
    MESSAGE="${UI_SET_FILE_PERMISSION} ${UI_GRAVITY_NAME}"
    echo_stat
    sudo chmod 664 ${LOCAL_PIHOLE_DIRECTORY}/${PH_GRAVITY_FI} >/dev/null 2>&1
    error_validate
}

## Validate Local DNS Records Permissions
function validate_custom_permissions() {
    MESSAGE="${UI_SET_LOCAL_FILE_OWNERSHIP} ${UI_CUSTOM_NAME}"
    echo_stat
    sudo chown root:root ${LOCAL_PIHOLE_DIRECTORY}/${PH_CUSTOM_DNS} >/dev/null 2>&1
    error_validate
    
    MESSAGE="${UI_SET_FILE_PERMISSION} ${UI_CUSTOM_NAME}"
    echo_stat
    sudo chmod 644 ${LOCAL_PIHOLE_DIRECTORY}/${PH_CUSTOM_DNS} >/dev/null 2>&1
    error_validate
}

## Validate Local DNS CNAME Permissions
function validate_cname_permissions() {
    MESSAGE="${UI_SET_LOCAL_FILE_OWNERSHIP} ${UI_CNAME_NAME}"
    echo_stat
    sudo chown root:root ${LOCAL_DNSMASQ_DIRECTORY}/${PH_CNAME_CONF} >/dev/null 2>&1
    error_validate
    
    MESSAGE="${UI_SET_FILE_PERMISSION} ${UI_CNAME_NAME}"
    echo_stat
    sudo chmod 644 ${LOCAL_DNSMASQ_DIRECTORY}/${PH_CNAME_CONF} >/dev/null 2>&1
    error_validate
}

## Validate Intent
function intent_validate {
    PHASER=$((( RANDOM % 4 ) + 1 ))
    if [ "$PHASER" = "1" ]; then
        INTENT="FIRE PHOTON TORPEDOS"
    elif [ "$PHASER" = "2" ]; then
        INTENT="FIRE ALL PHASERS"
    elif [ "$PHASER" = "3" ]; then
        INTENT="EJECT THE WARPCORE"
    elif [ "$PHASER" = "4" ]; then
        INTENT="ENGAGE TRACTOR BEAM"
    fi
    
    MESSAGE="Type ${INTENT} to confirm"
    echo_need
    
    read -r INPUT_INTENT
    
    if [ "${INPUT_INTENT}" != "${INTENT}" ]; then
        MESSAGE="${TASKTYPE} excited"
        echo_info
        exit_nochange
    fi
}

## Sudo Creation Task
function task_sudo {
    TASKTYPE='SUDO'
    MESSAGE="${MESSAGE}: ${TASKTYPE}"
    echo_good
    
    MESSAGE="Creating sudoers.d template file"
    echo_stat
    
    NEW_SUDO_USER=$(whoami)
    echo -e "${NEW_SUDO_USER} ALL=(ALL) NOPASSWD: ALL" | sudo tee ${GS_LOCAL_REPO}/templates/gs-nopasswd.sudo 1> /dev/null
    error_validate
    
    MESSAGE="Installing sudoers.d file on $HOSTNAME"
    echo_stat
    
    sudo install -m 0440 ${GS_LOCAL_REPO}/templates/gs-nopasswd.sudo /etc/sudoers.d/gs-nopasswd
    error_validate
    
    exit_withchange
}

## Root Check
function root_check {
    if [ ! "$EUID" -ne 0 ]; then
        TASKTYPE='ROOT'
        MESSAGE="${MESSAGE} ${TASKTYPE}"
        echo_fail
        
        MESSAGE="${PROGRAM} should not run as 'root'"
        echo_warn
        
        exit_nochange
    fi
}

function validate_sudo_status {
    CURRENTUSER=$(whoami)
    if [ ! "$EUID" -ne 0 ]; then
        LOCALADMIN=""
    else
        # Check Sudo
        SUDOCHECK=$(groups ${CURRENTUSER} | grep -e 'sudo' -e 'wheel')
        if [ "$SUDOCHECK" == "" ]; then
            LOCALADMIN="nosudo"
        else
            LOCALADMIN="sudo"
        fi
    fi
    
    if [ "$LOCALADMIN" == "nosudo" ]; then
        TASKTYPE='ROOT'
        MESSAGE="${MESSAGE} ${TASKTYPE}"
        echo_fail
        
        MESSAGE="${CURRENTUSER} has insufficent user rights for ${PROGRAM}"
        echo_warn
        
        exit_nochange
    fi
}

## Configure Task
function task_configure {				
    TASKTYPE='CONFIGURE'
    MESSAGE="${MESSAGE}: ${TASKTYPE}"
    echo_good
    
    if [ -f ${GS_ETC_PATH}/${GS_CONFIG_FILE} ]; then		
        config_delete
    else
        config_generate
    fi
    
    exit_withchange
}

## Generate New Configuration
function config_generate {  
    MESSAGE="${UI_CONFIG_CREATING} ${GS_CONFIG_FILE}"
    echo_stat
    sudo cp ${GS_LOCAL_REPO}/templates/${GS_CONFIG_FILE}.example ${GS_ETC_PATH}/${GS_CONFIG_FILE}
    error_validate
    
    echo_lines
    echo -e "Welcome to the ${PURPLE}Gravity Sync${NC} Configuration Wizard"
    echo -e "Please read through ${BLUE}https://github.com/vmstan/gravity-sync/wiki${NC} before you continue!"
    echo_blank
    echo -e "If the installer detects that you have a supported container engine (Docker or Podman) installed"
    echo -e "on your local ${UI_CORE_APP}, you will be directed to the advanced installation options. If you're using" 
    echo -e "containers on your remote ${UI_CORE_APP}, you'll need to select this option manually to adjust settings"
    echo -e "such as custom ${UI_CORE_APP} binary or configuration directories, CNAME replication, etc."
    echo_lines
    
    MESSAGE="${PROGRAM} ${UI_CONFIG_REQUIRED}"
    echo_info

    MESSAGE="${UI_CORE_APP} ${UI_CONFIG_REMOTE} ${UI_CONFIG_HOSTREQ}"
    echo_inf1

    MESSAGE="IP"
    echo_need
    read -r INPUT_REMOTE_HOST
    
    # MESSAGE="${UI_CONFIG_ICMP_TEST} ${INPUT_REMOTE_HOST}"
    # echo_stat
    # ping -c 3 ${INPUT_REMOTE_HOST} >/dev/null 2>&1
    # error_validate

    MESSAGE="${UI_CONFIG_SAVING} ${INPUT_REMOTE_HOST} host to ${GS_CONFIG_FILE}"
    echo_stat
    sudo sed -i "/REMOTE_HOST='192.168.1.10'/c\REMOTE_HOST='${INPUT_REMOTE_HOST}'" ${GS_ETC_PATH}/${GS_CONFIG_FILE}
    error_validate
    
    MESSAGE="${UI_CORE_APP} ${UI_CONFIG_REMOTE} ${UI_CONFIG_USERREQ} for ${INPUT_REMOTE_HOST}"
    echo_inf1

    MESSAGE="User"
    echo_need
    read -r INPUT_REMOTE_USER
    
    MESSAGE="${UI_CONFIG_SAVING} ${INPUT_REMOTE_USER}@${INPUT_REMOTE_HOST} user to ${GS_CONFIG_FILE}"
    echo_stat
    sudo sed -i "/REMOTE_USER='pi'/c\REMOTE_USER='${INPUT_REMOTE_USER}'" ${GS_ETC_PATH}/${GS_CONFIG_FILE}
    error_validate

    generate_sshkey
    
    MESSAGE="${UI_CORE_LOADING} ${GS_CONFIG_FILE}"
    echo_stat
    source ${GS_ETC_PATH}/${GS_CONFIG_FILE}
    error_validate

    echo_lines
    export_sshkey
    echo_lines

    MESSAGE="${UI_CONFIG_SSH_KEYPAIR} ${INPUT_REMOTE_HOST}"
    echo_good_clean

    MESSAGE="${UI_CONFIG_CONT_LOOKUP}"
    echo_stat

    docker_detect
    podman_detect

    if [ "${DOCKERREADY}" == "1" ] || [ "${PODMANREADY}" == "1" ]; then
        MESSAGE="${UI_CONFIG_CONT_DETECT} ${UI_CONFIG_CONT_DETECTED}"
        echo_good
        MESSAGE="${UI_CORE_LOADING} ${UI_CONFIG_ADVANCED}"
        echo_info
        advanced_config_generate
    else
        MESSAGE="${UI_CONFIG_CONT_DETECT} ${UI_CONFIG_CONT_DETECTNA}"
        echo_good
        MESSAGE="${UI_CONFIG_DOADVANCED}"
        echo_inf1
        MESSAGE="${UI_CONFIG_YESNON}"
        echo_need
        read -r INPUT_ADVANCED_INSTALL
        INPUT_ADVANCED_INSTALL="${INPUT_ADVANCED_INSTALL:-N}"
    
        if [ "${INPUT_ADVANCED_INSTALL}" == "Yes" ] || [ "${INPUT_ADVANCED_INSTALL}" == "yes" ] || [ "${INPUT_ADVANCED_INSTALL}" == "Y" ] || [ "${INPUT_ADVANCED_INSTALL}" == "y" ]; then
            MESSAGE="${UI_CORE_LOADING} ${UI_CONFIG_ADVANCED}"
            echo_info
        
            advanced_config_generate
        else 
            end_config
        fi
    fi
}

function end_config(){
    echo_lines
    echo -e "Configuration has been completed successfully, if you've still not read the instructions"
    echo -e "please read through ${BLUE}https://github.com/vmstan/gravity-sync/wiki${NC} before you continue!"
    echo_blank
    echo -e "Your next step is to complete a sync of data from your remote ${UI_CORE_APP} to this local ${UI_CORE_APP}."
    echo -e "ex: gravity-sync pull" 
    echo_blank
    echo -e "If this completes successfully you can automate future sync jobs to run at a regular interval."
    echo -e "ex: gravity-sync automate"
    echo_blank
    echo -e "Still confused? Please refer back to the documentation."
    echo_lines
}

## Advanced Configuration Options
function advanced_config_generate {
    MESSAGE="${UI_CONFIG_LOCALSEC} ${UI_CORE_APP} ${UI_CONFIG_INSTANCEREQ}"
    echo_inf1
    MESSAGE="${UI_CONFIG_INSTANCETYPE}"
    echo_need
    read -r INPUT_LOCAL_PIHOLE_TYPE
    INPUT_LOCAL_PIHOLE_TYPE="${INPUT_LOCAL_PIHOLE_TYPE:-default}"
    
    if [ "${INPUT_LOCAL_PIHOLE_TYPE}" != "default" ]; then
        if [ "${INPUT_LOCAL_PIHOLE_TYPE}" != "docker" ] && [ "${INPUT_LOCAL_PIHOLE_TYPE}" != "podman" ]; then
            MESSAGE="${UI_CONFIG_LOCALSEC} ${UI_CONFIG_INSTANCE_ERROR}"
            echo_warn
            exit_withchange
        fi

        MESSAGE="${UI_CONFIG_SAVING} ${UI_CONFIG_LOCAL} ${UI_CONFIG_CONTAINER_TYPE} to ${GS_CONFIG_FILE}"
        echo_stat
        sudo sed -i "/# LOCAL_PIHOLE_TYPE=''/c\LOCAL_PIHOLE_TYPE='${INPUT_LOCAL_PIHOLE_TYPE}'" ${GS_ETC_PATH}/${GS_CONFIG_FILE}
        error_validate
        
        MESSAGE="${UI_CONFIG_CONT_DETECT} ${UI_CONFIG_IMAGES}"
        echo_info
        echo_lines
        if [ "${INPUT_LOCAL_PIHOLE_TYPE}" == "docker" ]; then
            sudo docker container ls
        elif [ "${INPUT_LOCAL_PIHOLE_TYPE}" == "podman" ]; then
            sudo podman container ls
        fi
        echo_lines
        
        MESSAGE="${UI_CONFIG_LOCALSEC} ${UI_CORE_APP} ${UI_CONFIG_INSTANCENAME}"
        echo_inf1
        MESSAGE="${UI_CONFIG_PIHOLE_DEFAULT}"
        echo_need
        read -r INPUT_LOCAL_DOCKER_CONTAINER
        INPUT_LOCAL_DOCKER_CONTAINER="${INPUT_LOCAL_DOCKER_CONTAINER:-pihole}"
        
        if [ "${INPUT_LOCAL_DOCKER_CONTAINER}" != "pihole" ]; then
            MESSAGE="${UI_CONFIG_SAVING} ${UI_CONFIG_LOCAL} ${UI_CONFIG_CONTAINER_NAME} to ${GS_CONFIG_FILE}"
            echo_stat
            sudo sed -i "/# LOCAL_DOCKER_CONTAINER=''/c\LOCAL_DOCKER_CONTAINER='${INPUT_LOCAL_DOCKER_CONTAINER}'" ${GS_ETC_PATH}/${GS_CONFIG_FILE}
            error_validate
        fi
        
        MESSAGE="${UI_CONFIG_LOCALSEC} ${UI_CORE_APP} ${UI_CONFIG_ETC_VOLPATH}" 
        echo_inf1
        MESSAGE="${UI_CONFIG_ETC_VOLPATH_EXAMPLE}"
        echo_need
        read -r INPUT_LOCAL_PIHOLE_DIRECTORY
        
        if [ "${INPUT_LOCAL_PIHOLE_DIRECTORY}" != "" ]; then
            MESSAGE="${UI_CONFIG_SAVING} ${UI_CONFIG_LOCAL} ${UI_CORE_APP} ${UI_CONFIG_ETC_VOLPATH} to ${GS_CONFIG_FILE}"
            echo_stat
            sudo sed -i "/# LOCAL_PIHOLE_DIRECTORY=''/c\LOCAL_PIHOLE_DIRECTORY='${INPUT_LOCAL_PIHOLE_DIRECTORY}'" ${GS_ETC_PATH}/${GS_CONFIG_FILE}
            error_validate
        else
            MESSAGE="${UI_CONFIG_SETTING_REQUIRED}"
            echo_warn
            exit_withchange
        fi
        
        MESSAGE="${UI_CONFIG_LOCALSEC} ${UI_CORE_APP_DNS} ${UI_CONFIG_ETC_VOLPATH}"
        echo_inf1
        MESSAGE="${UI_CONFIG_ETC_VOLDNSQ_EXAMPLE}"
        echo_need
        read -r INPUT_LOCAL_DNSMASQ_DIRECTORY
        
        if [ "${INPUT_LOCAL_DNSMASQ_DIRECTORY}" != "" ]; then
            MESSAGE="${UI_CONFIG_SAVING} ${UI_CONFIG_LOCAL} ${UI_CORE_APP_DNS} ${UI_CONFIG_ETC_VOLPATH} to ${GS_CONFIG_FILE}"
            echo_stat
            sudo sed -i "/# LOCAL_DNSMASQ_DIRECTORY=''/c\LOCAL_DNSMASQ_DIRECTORY='${INPUT_LOCAL_DNSMASQ_DIRECTORY}'" ${GS_ETC_PATH}/${GS_CONFIG_FILE}
            error_validate
        else
            MESSAGE="${UI_CONFIG_SETTING_REQUIRED}"
            echo_warn
            exit_withchange
        fi
        
        MESSAGE="${UI_CONFIG_SAVING} ${UI_CONFIG_LOCAL} ${UI_CONFIG_VOLUME_OWNER} to ${GS_CONFIG_FILE}"
        echo_stat
        sudo sed -i "/# LOCAL_FILE_OWNER=''/c\LOCAL_FILE_OWNER='999:999'" ${GS_ETC_PATH}/${GS_CONFIG_FILE}
        error_validate
    fi
    
    MESSAGE="${UI_CONFIG_REMOTEPRI} ${UI_CORE_APP} ${UI_CONFIG_INSTANCEREQ}"
    echo_inf1
    MESSAGE="${UI_CONFIG_INSTANCETYPE}"
    echo_need
    read -r INPUT_REMOTE_PIHOLE_TYPE
    INPUT_REMOTE_PIHOLE_TYPE="${INPUT_REMOTE_PIHOLE_TYPE:-default}"
    
    if [ "${INPUT_REMOTE_PIHOLE_TYPE}" != "default" ]; then
        if [ "${INPUT_REMOTE_PIHOLE_TYPE}" != "docker" ] && [ "${INPUT_REMOTE_PIHOLE_TYPE}" != "podman" ]; then
            MESSAGE="${UI_CONFIG_REMOTEPRI} ${UI_CONFIG_INSTANCE_ERROR}"
            echo_warn
            exit_withchange
        fi

        MESSAGE="${UI_CONFIG_SAVING} ${UI_CONFIG_REMOTE} ${UI_CONFIG_CONTAINER_TYPE} to ${GS_CONFIG_FILE}"
        echo_stat
        sudo sed -i "/# REMOTE_PIHOLE_TYPE=''/c\REMOTE_PIHOLE_TYPE='${INPUT_REMOTE_PIHOLE_TYPE}'" ${GS_ETC_PATH}/${GS_CONFIG_FILE}
        error_validate
        
        MESSAGE="${UI_CONFIG_REMOTEPRI} ${UI_CONFIG_CONTAINER_NAME}"
        echo_inf1
        MESSAGE="${UI_CONFIG_DEFAULT_LEAVE} 'pihole'"
        echo_need
        read -r INPUT_REMOTE_DOCKER_CONTAINER
        INPUT_REMOTE_DOCKER_CONTAINER="${INPUT_REMOTE_DOCKER_CONTAINER:-pihole}"
        
        if [ "${INPUT_REMOTE_DOCKER_CONTAINER}" != "pihole" ]; then
            MESSAGE="${UI_CONFIG_SAVING} ${UI_CONFIG_REMOTE} ${UI_CONFIG_CONTAINER_NAME} to ${GS_CONFIG_FILE}"
            echo_stat
            sudo sed -i "/# REMOTE_DOCKER_CONTAINER=''/c\REMOTE_DOCKER_CONTAINER='${INPUT_REMOTE_DOCKER_CONTAINER}'" ${GS_ETC_PATH}/${GS_CONFIG_FILE}
            error_validate
        fi
        
        MESSAGE="${UI_CONFIG_REMOTEPRI} ${UI_CORE_APP} ${UI_CONFIG_ETC_VOLPATH}"
        echo_inf1
        MESSAGE="${UI_CONFIG_ETC_VOLPATH_EXAMPLE}"
        echo_need
        read -r INPUT_REMOTE_PIHOLE_DIRECTORY
        
        if [ "${INPUT_REMOTE_PIHOLE_DIRECTORY}" != "" ]; then
            MESSAGE="${UI_CONFIG_SAVING} ${UI_CONFIG_REMOTE} ${UI_CORE_APP} ${UI_CONFIG_ETC_VOLPATH} to ${GS_CONFIG_FILE}"
            echo_stat
            sudo sed -i "/# REMOTE_PIHOLE_DIRECTORY=''/c\REMOTE_PIHOLE_DIRECTORY='${INPUT_REMOTE_PIHOLE_DIRECTORY}'" ${GS_ETC_PATH}/${GS_CONFIG_FILE}
            error_validate
        else
            MESSAGE="${UI_CONFIG_SETTING_REQUIRED}"
            echo_warn
            exit_withchange
        fi
        
        MESSAGE="${UI_CONFIG_REMOTEPRI} ${UI_CORE_APP_DNS} ${UI_CONFIG_ETC_VOLPATH}"
        echo_inf1
        MESSAGE="${UI_CONFIG_ETC_VOLDNSQ_EXAMPLE}"
        echo_need
        read -r INPUT_REMOTE_DNSMASQ_DIRECTORY
        
        if [ "${INPUT_REMOTE_DNSMASQ_DIRECTORY}" != "" ]; then
            MESSAGE="${UI_CONFIG_SAVING} ${UI_CONFIG_REMOTE} ${UI_CORE_APP_DNS} ${UI_CONFIG_ETC_VOLPATH} to ${GS_CONFIG_FILE}"
            echo_stat
            sudo sed -i "/# REMOTE_DNSMASQ_DIRECTORY=''/c\REMOTE_DNSMASQ_DIRECTORY='${INPUT_REMOTE_DNSMASQ_DIRECTORY}'" ${GS_ETC_PATH}/${GS_CONFIG_FILE}
            error_validate
        else
            MESSAGE="${UI_CONFIG_SETTING_REQUIRED}"
            echo_warn
            exit_withchange
        fi
        
        MESSAGE="${UI_CONFIG_SAVING} ${UI_CONFIG_REMOTE} ${UI_CONFIG_VOLUME_OWNER} to ${GS_CONFIG_FILE}"
        echo_stat
        sudo sed -i "/# REMOTE_FILE_OWNER=''/c\REMOTE_FILE_OWNER='999:999'" ${GS_ETC_PATH}/${GS_CONFIG_FILE}
        error_validate
    fi

    end_config
}

function task_cname {
    TASKTYPE='CNAME'
    MESSAGE="${MESSAGE}: ${TASKTYPE}"
    echo_good

    config_enablecname
    exit_withchange
}

## Delete Existing Configuration
function config_delete {
    source ${GS_ETC_PATH}/${GS_CONFIG_FILE}
    MESSAGE="${GS_CONFIG_FILE} ${UI_CONFIG_ALREADY}"
    echo_info  
  
    MESSAGE="${UI_CONFIG_AREYOUSURE}"
    echo_inf1

    intent_validate

    MESSAGE="${UI_CONFIG_ERASING} ${GS_CONFIG_FILE}"
    echo_stat
    sudo mv ${GS_ETC_PATH}/${GS_CONFIG_FILE} ${GS_ETC_PATH}/${GS_CONFIG_FILE}.${GS_BACKUP_EXT}
        error_validate

    config_generate
}

## Detect Docker
function docker_detect {
    if hash docker 2>/dev/null; then
        FTLCHECK=$(sudo docker container ls | grep 'pihole/pihole')
        if [ "$FTLCHECK" != "" ]; then
            DOCKERREADY="1"
        fi
    fi
}

## Detect Podman
function podman_detect {
    if hash podman 2>/dev/null; then
        FTLCHECK=$(sudo podman container ls | grep 'pihole/pihole')
        if [ "$FTLCHECK" != "" ]; then
            PODMANREADY="1"
        fi
    fi
}

## Master Branch
function update_gs {
    echo_lines
        bash ${GS_LOCAL_REPO}/update.sh
    echo_lines
}

## Show Version
function show_version {
    if [ -f ${GS_LOCAL_REPO}/dev ]; then
        DEVVERSION="-dev"
    else
        DEVVERSION=""
    fi
    
    MESSAGE="Running version: ${GREEN}${VERSION}${NC}${DEVVERSION}"
    echo_info
    
    GITVERSION=$(curl -sf https://raw.githubusercontent.com/vmstan/gravity-sync/master/VERSION)
    if [ -z "$GITVERSION" ]; then
        MESSAGE="Latest version: ${RED}Unknown${NC}"
    else
        if [ "$GITVERSION" != "$VERSION" ]; then
            MESSAGE="Update available: ${RED}${GITVERSION}${NC}"
        else
            MESSAGE="Latest version: ${GREEN}${GITVERSION}${NC}"
        fi
    fi
    echo_info
}

function show_info() {
    echo_lines
    echo -e "${YELLOW}Local Software Versions${NC}"
    echo -e "${BLUE}${UI_CORE_APP}${NC}"
    if [ "${LOCAL_PIHOLE_TYPE}" == "default" ]; then
        pihole version
    elif [ "${LOCAL_PIHOLE_TYPE}" == "docker" ]; then 
        sudo docker exec -it pihole pihole -v
    elif [ "${LOCAL_PIHOLE_TYPE}" == "podman" ]; then 
        sudo podman exec -it pihole pihole -v
    fi
    
    lsb_release -d
    uname -srm
    echo -e "bash $BASH_VERSION"
    ssh -V
    rsync --version | grep version
    sudo --version | grep "Sudo version"
    git --version
    
    if hash docker 2>/dev/null; then
        docker --version
    fi

    if hash podman 2>/dev/null; then
        podman --version
    fi

    echo -e ""
    
    echo -e "${YELLOW}Global Instance Settings${NC}"
    if [ ${GS_SSH_PORT} == '22' ]; then
        echo -e "SSH Port: 22 (default)"
    else
        echo -e "SSH Port: ${GS_SSH_PORT} (custom)"
    fi

    echo -e "SSH Keyfile: ${GS_SSH_PKIF}"

    if systemctl is-active --quiet gravity-sync.timer; then
        echo -e "Automated Replication: Enabled"
    else
        echo -e "Automated Replication: Disabled"
    fi

    echo -e ""

    echo -e "${YELLOW}Local Instance Settings${NC}"
    echo -e "Local Hostname: $HOSTNAME"
    echo -e "Local ${UI_CORE_APP} Type: ${LOCAL_PIHOLE_TYPE}"
    echo -e "Local ${UI_CORE_APP} Config Directory: ${LOCAL_PIHOLE_DIRECTORY}"
    echo -e "Local DNSMASQ Config Directory: ${LOCAL_DNSMASQ_DIRECTORY}"
    echo -e "Local Gravity Sync Binary: ${GS_FILEPATH}"
    echo -e "Local Gravity Sync Config Directory: ${GS_ETC_PATH}"
    
    if [ "${LOCAL_PIHOLE_TYPE}" == "default" ]; then
        echo -e "Local ${UI_CORE_APP} Binary Directory: ${LOCAL_PIHOLE_BINARY}"
    elif [ "${LOCAL_PIHOLE_TYPE}" == "docker" ]; then 
        echo -e "Local ${UI_CORE_APP} Container Name: ${LOCAL_DOCKER_CONTAINER}"
        echo -e "Local Docker Binary Directory: ${LOCAL_DOCKER_BINARY}"
    elif [ "${LOCAL_PIHOLE_TYPE}" == "podman" ]; then 
        echo -e "Local ${UI_CORE_APP} Container Name: ${LOCAL_DOCKER_CONTAINER}"
        echo -e "Local Podman Binary Directory: ${LOCAL_PODMAN_BINARY}"
    fi
    
    echo -e "Local File Owner Settings: ${LOCAL_FILE_OWNER}"
        
    echo -e ""
    echo -e "${YELLOW}Remote Instance Settings${NC}"
    echo -e "Remote Hostname/IP: ${REMOTE_HOST}"
    echo -e "Remote Username: ${REMOTE_USER}"
    echo -e "Remote ${UI_CORE_APP} Type: ${REMOTE_PIHOLE_TYPE}"
    echo -e "Remote ${UI_CORE_APP} Config Directory: ${REMOTE_PIHOLE_DIRECTORY}"
    echo -e "Remote DNSMASQ Config Directory: ${REMOTE_DNSMASQ_DIRECTORY}"

    if [ "${REMOTE_PIHOLE_TYPE}" == "default" ]; then
        echo -e "Remote ${UI_CORE_APP} Binary Directory: ${REMOTE_PIHOLE_BINARY}"
    elif [ "${REMOTE_PIHOLE_TYPE}" == "docker" ]; then 
        echo -e "Remote ${UI_CORE_APP} Container Name: ${REMOTE_DOCKER_CONTAINER}"
        echo -e "Remote Docker Binary Directory: ${REMOTE_DOCKER_BINARY}"
    elif [ "${REMOTE_PIHOLE_TYPE}" == "podman" ]; then 
        echo -e "Remote ${UI_CORE_APP} Container Name: ${REMOTE_DOCKER_CONTAINER}"
        echo -e "Remote Podman Binary Directory: ${REMOTE_PODMAN_BINARY}"
    fi

    echo -e "Remote File Owner Settings: ${REMOTE_FILE_OWNER}"
    echo_lines
}

## Devmode Task
function task_devmode {
    TASKTYPE='DEV'
    MESSAGE="${MESSAGE}: ${TASKTYPE}"
    echo_good
    
    if [ -f ${GS_LOCAL_REPO}/dev ]; then
        MESSAGE="Disabling ${TASKTYPE}"
        echo_stat
        sudo rm -f ${GS_LOCAL_REPO}/dev
        error_validate
    else
        MESSAGE="Enabling ${TASKTYPE}"
        echo_stat
        touch ${GS_LOCAL_REPO}/dev
        error_validate
        
        MESSAGE="Checking available branches"
        echo_stat
        (cd ${GS_LOCAL_REPO} || exit; git fetch --all >/dev/null 2>&1)
        error_validate
        
        (cd ${GS_LOCAL_REPO} || exit; git branch -r)
        
        MESSAGE="Select GitHub branch to update against"
        echo_need
        read -r INPUT_BRANCH
        
        echo -e "BRANCH='${INPUT_BRANCH}'" | sudo tee ${GS_LOCAL_REPO}/dev 1> /dev/null
    fi
    
    update_gs
    exit_withchange
}

## Update Task
function task_update {
    TASKTYPE='UPDATE'
    MESSAGE="${MESSAGE}: ${TASKTYPE}"
    echo_good
    update_gs
    exit_withchange
}

## Version Task
function task_version {
    TASKTYPE='VERSION'
    MESSAGE="${MESSAGE}: ${TASKTYPE}"
    echo_good
    show_version
    exit_nochange
}

## Info Task

function task_info() {
    TASKTYPE='INFO'
    MESSAGE="${MESSAGE}: ${TASKTYPE}"
    echo_good
    show_info
    exit_nochange
}

## Automate Task
function task_automate {
    TASKTYPE='AUTOMATE'
    MESSAGE="${MESSAGE}: ${TASKTYPE}"
    echo_good

    MESSAGE="Customizing service file username"
    CURRENTUSER=$(whoami)
    sudo sed -i "/User=unknown/c\User=${CURRENTUSER}" ${GS_LOCAL_REPO}/templates/gravity-sync.service
    error_validate

    MESSAGE="Customizing service file executable path"
    sudo sed -i "/ExecStart=/c\ExecStart=${GS_FILEPATH}" ${GS_LOCAL_REPO}/templates/gravity-sync.service
    error_validate

    MESSAGE="Randomizing service timers"
    ACTIVE_REP=$((( RANDOM % 4 ) + 1 ))
    RANDOM_REP=$((( RANDOM % 8 ) + 2 ))
    sudo sed -i "/OnUnitInactiveSec=5m/c\OnUnitInactiveSec=${ACTIVE_REP}m" ${GS_LOCAL_REPO}/templates/gravity-sync.timer
    sudo sed -i "/RandomizedDelaySec=5m/c\RandomizedDelaySec=${RANDOM_REP}m" ${GS_LOCAL_REPO}/templates/gravity-sync.timer
    error_validate

    if systemctl is-active --quiet gravity-sync; then
        MESSAGE="Stopping existing systemd service"
        sudo systemctl stop gravity-sync
        error_validate
    fi

    MESSAGE="Moving systemd timer into place"
    sudo cp ${GS_LOCAL_REPO}/templates/gravity-sync.timer ${OS_DAEMON_PATH}
    error_validate

    MESSAGE="Moving systemd service into place"
    sudo cp ${GS_LOCAL_REPO}/templates/gravity-sync.service ${OS_DAEMON_PATH}
    error_validate

    MESSAGE="Reloading systemd daemon"
    sudo systemctl daemon-reload --quiet
    error_validate

    MESSAGE="Enabling Gravity Sync timer"
    sudo systemctl enable gravity-sync.timer --quiet
    error_validate

    MESSAGE="Starting Gravity Sync service"
    sudo systemctl start gravity-sync --quiet
    error_validate
    
    exit_withchange
}

## Purge Task
function task_purge {
    TASKTYPE="PURGE"
    MESSAGE="${MESSAGE}: ${TASKTYPE}"
    echo_good
    
    echo_lines
    echo -e "THIS WILL REMOVE YOUR GRAVITY SYNC INSTALLATION"
    echo -e "${UI_CORE_APP} binaries, configuration and services ARE NOT impacted!"
    echo -e "Your devices will continue to resolve and block DNS requests,"
    echo -e "but your ${UI_GRAVITY_NAME} and ${UI_CUSTOM_NAME} WILL NOT sync anymore,"
    echo -e "until you reconfigure Gravity Sync on this device. Backup files will not"
    echo -e "be removed but you can manually remove '.${GS_BACKUP_EXT}' files if desired."
    echo_lines
        
    intent_validate
    
    # MESSAGE="${UI_PURGE_CLEANING_DIR}"
    # echo_stat
    # backup_cleanup

    sudo systemctl stop gravity-sync.timer
    sudo systemctl disable gravity-sync
    
    sudo rm -fr ${GS_ETC_PATH}
    sudo rm ${GS_FILEPATH}
    exit_withchange
}

## No Changes Made
function exit_nochange {
    SCRIPT_END=$SECONDS
    let SCRIPT_RUN=SCRIPT_END-SCRIPT_START
    
    if [ "${TASKTYPE}" == "" ]; then
        MESSAGE="${PROGRAM} ${UI_EXIT_ABORT} ${UI_EXIT_CALC_END} ${SCRIPT_RUN} ${UI_EXIT_CALC_TIMER}"
    else
        MESSAGE="${PROGRAM} ${TASKTYPE} ${UI_EXIT_ABORT} ${UI_EXIT_CALC_END} ${SCRIPT_RUN} ${UI_EXIT_CALC_TIMER}"
    fi
    
    echo_grav
    exit 0
}

## Changes Made
function exit_withchange {
    SCRIPT_END=$SECONDS
    let SCRIPT_RUN=SCRIPT_END-SCRIPT_START
    
    if [ "${TASKTYPE}" == "" ]; then
        MESSAGE="${PROGRAM} ${UI_EXIT_COMPLETE} ${UI_EXIT_CALC_END} ${SCRIPT_RUN} ${UI_EXIT_CALC_TIMER}"
    else
        MESSAGE="${PROGRAM} ${TASKTYPE} ${UI_EXIT_COMPLETE} ${UI_EXIT_CALC_END} ${SCRIPT_RUN} ${UI_EXIT_CALC_TIMER}"
    fi
    
    echo_grav
    exit 0
}

## List GS Arguments
function list_gs_arguments {
    echo -e "Usage: $0 [options]"
    echo -e "Example: '$0 pull'"
    echo_lines
    echo -e "Setup Options:"
    echo -e " ${YELLOW}config${NC}      Creates a new ${PROGRAM} configuration file"
    echo -e " ${YELLOW}automate${NC}    Schedules the ${PROGRAM} replication task using systemd"
    echo -e " ${YELLOW}version${NC}     Shows the installed version of ${PROGRAM} and check for updates"
    echo -e " ${YELLOW}update${NC}      Upgrades ${PROGRAM} to the latest available version using Git"
    echo -e " ${YELLOW}dev${NC}         Sets update command to use a development version of ${PROGRAM}"
    echo -e " ${YELLOW}sudo${NC}        Configures passwordless sudo for current user"
    echo_blank
    echo -e "Replication Options:"
    echo -e " ${YELLOW}smart${NC}       Detects ${UI_CORE_APP} changes on remote and local and then combines them"
    echo -e " ${YELLOW}pull${NC}        Brings the remote ${UI_CORE_APP} configuration to this server"
    echo -e " ${YELLOW}push${NC}        Sends the local ${UI_CORE_APP} configuration to the remote"
    echo -e " ${YELLOW}compare${NC}     Just checks for ${UI_CORE_APP} differences at each side without making changes"
    echo_blank
    echo -e "Debug Options:"
    echo -e " ${YELLOW}logs${NC}        Shows the recent successful replication jobs/times"
    echo -e " ${YELLOW}info${NC}        Shows information about the current configuration"
    echo_lines
    exit_nochange
}

# SCRIPT EXECUTION ###########################

case $# in
    0)
        start_gs
        task_smart ;;
    1)
        case $1 in
            smart|sync)
                start_gs
                task_smart ;;
            pull)
                start_gs
                task_pull ;;
            push)
                start_gs
                task_push ;;
            version)
                start_gs_noconfig
                task_version ;;
            update|upgrade)
                start_gs_noconfig
                task_update ;;
            dev|devmode|development|develop)
                start_gs_noconfig
                task_devmode ;;
            logs|log)
                start_gs
                task_logs ;;
            compare)
                start_gs
                task_compare ;;
            config|configure)
                start_gs_noconfig
                task_configure ;;
            auto|automate)
                start_gs
                task_automate ;;
            purge|uninstall|remove)
                start_gs
                task_purge ;;
            sudo)
                start_gs
                task_sudo ;;
            info)
                start_gs
                task_info ;;
            cname)
                start_gs
                task_cname ;;    
            *)
                start_gs
                task_invalid ;;
        esac
    ;;
    
    *)
        start_gs
        task_invalid ;;
esac

# END OF SCRIPT ##############################
